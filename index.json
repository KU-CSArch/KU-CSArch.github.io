[{"authors":["yujin-kim"],"categories":null,"content":"Yujin Kim is a graduate student pursuing a Master’s degree in the Department of Computer Science and Engineering at Korea University. Her research interest is in computer architecture and accelerator architecture. Her current research focuses on AI accelerator architecture design.\nYujin earned her B.S. degree in Electronic Engineering at Soongsil University, South Korea.\n","date":1693526400,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1693526400,"objectID":"194f6cb9ec6f69250dc20794dbd55b25","permalink":"https://ku-csarch.github.io/authors/yujin-kim/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/yujin-kim/","section":"authors","summary":"Yujin Kim is a graduate student pursuing a Master’s degree in the Department of Computer Science and Engineering at Korea University. Her research interest is in computer architecture and accelerator architecture.","tags":null,"title":"Yujin Kim","type":"authors"},{"authors":["\u003cUSERNAME\u003e"],"categories":null,"content":"Gunjae Koo is an associate professor in the Department of Computer Science and Engineering at Korea University. His research interest is in computer architecture, memory systems, storage systems, and accelerator design. His current research focuses on memory systems of parallel processors and near data processing on storage platforms.\nGunjae completed his Ph.D. in the Department of Electrical Engineering at the University of Southern California (USC) working with Professor Murali Annavaram. He earned his B.S. and M.S. degrees in Electrical and Computer Engineering at Seoul National University, South Korea. Before joining Korea University, he was an assistant professor at Hongik University. He worked for LG Electronics Digital TV and System IC laboratory as a senior research engineer involved in multiple research projects developing SoCs for storage devices and digital TVs. He also worked on the memory controller architecture for high-performance server systems at Intel.\n","date":1691625600,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1691625600,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://ku-csarch.github.io/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"Gunjae Koo is an associate professor in the Department of Computer Science and Engineering at Korea University. His research interest is in computer architecture, memory systems, storage systems, and accelerator design.","tags":null,"title":"Gunjae Koo","type":"authors"},{"authors":["jonghyun-jeong"],"categories":null,"content":"Jonghyun Jeong is a graduate student pursuing a Master’s degree in the Department of Computer Science and Engineering at Korea University. His research interest is in GPGPU. His current research focuses on memory systems of GPU.\nJonghyun earned his B.S. degree in Electronic and Electrical Engineering and Computer Engineering (Double Major) at Hongik University, South Korea. Before entering Korea University, he worked as a undergraduate researcher for 1.5 years at Hongik University.\n","date":1691625600,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1691625600,"objectID":"f30b70d895d38eba84113ce1ef78e1ad","permalink":"https://ku-csarch.github.io/authors/jonghyun-jeong/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/jonghyun-jeong/","section":"authors","summary":"Jonghyun Jeong is a graduate student pursuing a Master’s degree in the Department of Computer Science and Engineering at Korea University. His research interest is in GPGPU. His current research focuses on memory systems of GPU.","tags":null,"title":"Jonghyun Jeong","type":"authors"},{"authors":["hyunwoo-moon"],"categories":null,"content":"Hyunwoo Moon is a graduate student pursuing a Master’s degree in the Department of Computer Science and Engineering at Korea University. His research interests lie in memory systems and domain specific architectures.\n","date":1687219200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1687219200,"objectID":"5f1f0be50daba09c24550dd8a0f69585","permalink":"https://ku-csarch.github.io/authors/hyunwoo-moon/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/hyunwoo-moon/","section":"authors","summary":"Hyunwoo Moon is a graduate student pursuing a Master’s degree in the Department of Computer Science and Engineering at Korea University. His research interests lie in memory systems and domain specific architectures.","tags":null,"title":"Hyunwoo Moon","type":"authors"},{"authors":["hungjong-lee"],"categories":null,"content":"Hunjong Lee is a graduate student pursuing a Master’s degree in the Department of Computer Science and Engineering at Korea University. His research interests lie in computer architecture and accelerator design. His current research focuses on DNN accelerator architecture.\nHunjong earned his B.S. in Electronic \u0026amp; Electrical Engineering at Hongik University, South Korea.\n","date":1686182400,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1686182400,"objectID":"40cd99038d5367cf60fc8c8dd80fed80","permalink":"https://ku-csarch.github.io/authors/hunjong-lee/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/hunjong-lee/","section":"authors","summary":"Hunjong Lee is a graduate student pursuing a Master’s degree in the Department of Computer Science and Engineering at Korea University. His research interests lie in computer architecture and accelerator design.","tags":null,"title":"Hunjong Lee","type":"authors"},{"authors":["inje-kim"],"categories":null,"content":"Inje Kim is a graduate student pursuing a Master’s degree in the Department of Computer Science and Engineering at Korea University. His research interest is in accelerator architectures, GPGPU, graph neural networks (GNNs). His current research focuses on characterizing graph neural networks on GPGPU and acceleration of graph neural networks.\nInje earned his B.S. degree in Electronic \u0026amp; Electrical Engineering at Hongik University. Before entering Korea University, he worked as a undergraduate researcher for two years at Hongik University.\n","date":1681516800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1681516800,"objectID":"8f59d9d90b034fab23c0cabdd2e60d51","permalink":"https://ku-csarch.github.io/authors/inje-kim/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/inje-kim/","section":"authors","summary":"Inje Kim is a graduate student pursuing a Master’s degree in the Department of Computer Science and Engineering at Korea University. His research interest is in accelerator architectures, GPGPU, graph neural networks (GNNs).","tags":null,"title":"Inje Kim","type":"authors"},{"authors":["dowon-kwon"],"categories":null,"content":"Dowon Kwon is a graduate student pursuing a Master’s degree in Department of Computer Science and Engineering at Korea University. His research interest lies in computer architecture and software engineering.\nDowon earned his B.S. in Oceanography and Military Science at Republic of Korea Naval Academy, South Korea.\n","date":1677628800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1677628800,"objectID":"1b9d2282bb58b7a99bb3fea02d3f00ae","permalink":"https://ku-csarch.github.io/authors/dowon-kwon/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/dowon-kwon/","section":"authors","summary":"Dowon Kwon is a graduate student pursuing a Master’s degree in Department of Computer Science and Engineering at Korea University. His research interest lies in computer architecture and software engineering.","tags":null,"title":"Dowon Kwon","type":"authors"},{"authors":["geonwoo-choi"],"categories":null,"content":"Geonwoo Choi is a graduate student pursuing a Master’s degree in Department of Computer Science and Engineering at Korea University. His reserch interest is in GPGPU architecture and parallel processor architecture.\nGeonwoo completed his B.S in the Electrical and Electronics Engineering at Chung-Ang University, South Korea.\n","date":1677628800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1677628800,"objectID":"5546fc9ebb967082451fa822ed5daf08","permalink":"https://ku-csarch.github.io/authors/geonwoo-choi/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/geonwoo-choi/","section":"authors","summary":"Geonwoo Choi is a graduate student pursuing a Master’s degree in Department of Computer Science and Engineering at Korea University. His reserch interest is in GPGPU architecture and parallel processor architecture.","tags":null,"title":"Geonwoo Choi","type":"authors"},{"authors":["jiwon-shin"],"categories":null,"content":"Jiwon Shin is a graduate student pursuing a Master’s degree in the Department of Computer Science and Engineering at Korea University. Her research interest lies in computer architecture and memory/storage systems.\nJiwon earned her B.S. degree in the Electrical and Electronics Engineering at the Chung-Ang University, South Korea.\n","date":1677628800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1677628800,"objectID":"f85e81c71a5bbcfa862ea9ae3428fc74","permalink":"https://ku-csarch.github.io/authors/jiwon-shin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/jiwon-shin/","section":"authors","summary":"Jiwon Shin is a graduate student pursuing a Master’s degree in the Department of Computer Science and Engineering at Korea University. Her research interest lies in computer architecture and memory/storage systems.","tags":null,"title":"Jiwon Shin","type":"authors"},{"authors":["taewoon-kang"],"categories":null,"content":"Taewoon Kang is a graduate student pursuing a Master’s degree (Ph.D./Masters integrated course) in Department of Computer Science and Engineering at Korea University. His research interest lies in near data processing (NDP) and FPGA-based accelerator design. His current research focuses on accelerator architecture and processing-in-memory (PIM).\nTaewoon completed his B.S. in System-Semiconductor Engineering at Sangmyung University, South Korea.\n","date":1677628800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1677628800,"objectID":"07606a5bb55ac5c739f2a2bedb2aa040","permalink":"https://ku-csarch.github.io/authors/taewoon-kang/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/taewoon-kang/","section":"authors","summary":"Taewoon Kang is a graduate student pursuing a Master’s degree (Ph.D./Masters integrated course) in Department of Computer Science and Engineering at Korea University. His research interest lies in near data processing (NDP) and FPGA-based accelerator design.","tags":null,"title":"Taewoon Kang","type":"authors"},{"authors":["yujin-lee"],"categories":null,"content":"Yujin Lee is a graduate student pursuing a Master’s degree in the Department of Computer Science and Engineering at Korea University. Her research interest lies in computer architecture and accelerators.\nYujin completed her B.S. in the Electronic \u0026amp; Electrical Engineering at Hongik University, South Korea.\n","date":1677628800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1677628800,"objectID":"342ff49908101bdf90fcbc76b270f6a8","permalink":"https://ku-csarch.github.io/authors/yujin-lee/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/yujin-lee/","section":"authors","summary":"Yujin Lee is a graduate student pursuing a Master’s degree in the Department of Computer Science and Engineering at Korea University. Her research interest lies in computer architecture and accelerators.","tags":null,"title":"Yujin Lee","type":"authors"},{"authors":["boyoung-park"],"categories":null,"content":"Boyoung Park is a graduate student pursuing a Master’s degree in the Department of Computer Science and Engineering at Korea University. Her research interest lies in near data processing and memory/storage systems. Her current research focuses on accelerating genomic analysis accommodating near data processing on storage platforms.\nBoyoung completed her B.S. in the Electronic \u0026amp; Electrical Engineering at Hongik University, South Korea.\n","date":1677196800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1677196800,"objectID":"8d78d4cab9e48201e9ffbdf0faed3afc","permalink":"https://ku-csarch.github.io/authors/boyoung-park/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/boyoung-park/","section":"authors","summary":"Boyoung Park is a graduate student pursuing a Master’s degree in the Department of Computer Science and Engineering at Korea University. Her research interest lies in near data processing and memory/storage systems.","tags":null,"title":"Boyoung Park","type":"authors"},{"authors":["jongmin-lee"],"categories":null,"content":"Jongmin Lee is a software engineer at the Memory Business Division of Samsung Electronics. His research interest is in computer architecture and trusted computing. His current research focuses on performance efficient software for storage systems.\nJongmin Lee earned his Ph.D. degree in the Department of Computer Science and Engineering at Korea University under the supervision of Prof. Gunjae Koo. He earned his B.S. and M.S. degrees in Computer Engineering at Korea University, South Korea. He worked for TMAX OS as a reseacher invloved in multiple projects developing operating systems and software frameworks.\n","date":1677196800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1677196800,"objectID":"40ff7f58a64175cfed8595b51741ac94","permalink":"https://ku-csarch.github.io/authors/jongmin-lee/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/jongmin-lee/","section":"authors","summary":"Jongmin Lee is a software engineer at the Memory Business Division of Samsung Electronics. His research interest is in computer architecture and trusted computing. His current research focuses on performance efficient software for storage systems.","tags":null,"title":"Jongmin Lee","type":"authors"},{"authors":["seungho-jung"],"categories":null,"content":"Seungho Jung is a graduate student pursuing a Master’s degree in the Department of Computer Science and Engineering at Korea University supervised by Professor Gunjae Koo. His research interests lie in GPU architecture, memory systems (especially HBMs), storage systems, and secure architecture. His current research focuses on secure GPU architecture on specific application.\nHe completed his B.S. in the Electronic \u0026amp; Electrical Engineering at the Hongik University.\n","date":1677196800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1677196800,"objectID":"82253009e81678bf573cd7ea03fd7ac4","permalink":"https://ku-csarch.github.io/authors/seungho-jung/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/seungho-jung/","section":"authors","summary":"Seungho Jung is a graduate student pursuing a Master’s degree in the Department of Computer Science and Engineering at Korea University supervised by Professor Gunjae Koo. His research interests lie in GPU architecture, memory systems (especially HBMs), storage systems, and secure architecture.","tags":null,"title":"Seungho Jung","type":"authors"},{"authors":["jaewon-seo"],"categories":null,"content":"Jaewon Seo is a graduate student pursuing a Master’s degree in the Department of Computer Science and Engineering at Korea University. His research interest lies in computer architecture, near data processing, and memory/storage systems. His current research focuses on smart storage systems.\nJaewon completed his B.S. in the Mathematics at Kookmin University, South Korea.\n","date":1675641600,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1675641600,"objectID":"bfcc6754e20f7ce8bf56f0b26349f32b","permalink":"https://ku-csarch.github.io/authors/jaewon-seo/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/jaewon-seo/","section":"authors","summary":"Jaewon Seo is a graduate student pursuing a Master’s degree in the Department of Computer Science and Engineering at Korea University. His research interest lies in computer architecture, near data processing, and memory/storage systems.","tags":null,"title":"Jaewon Seo","type":"authors"},{"authors":["yewon-hwang"],"categories":null,"content":"Yewon Hwang is a graduate student pursuing a Master’s degree (Ph.D./Masters integrated course) in the Department of Computer Science and Engineering at Korea University. Her research interest lies in computer architecture and memory/storage systems. Her current research focuses on processr design using open-source ISAs.\nYewon completed her B.S. in the Electronic Engineering at Korea National University of Transportation, South Korea.\n","date":1675641600,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1675641600,"objectID":"8095c19b4e79bf24c69cdc77690b1e7f","permalink":"https://ku-csarch.github.io/authors/yewon-hwang/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/yewon-hwang/","section":"authors","summary":"Yewon Hwang is a graduate student pursuing a Master’s degree (Ph.D./Masters integrated course) in the Department of Computer Science and Engineering at Korea University. Her research interest lies in computer architecture and memory/storage systems.","tags":null,"title":"Yewon Hwang","type":"authors"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature.   Slides can be added in a few ways:\n Create slides using Wowchemy’s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes.  Further event details, including page elements such as image galleries, can be added to the body of this page.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"a8edef490afe42206247b6ac05657af0","permalink":"https://ku-csarch.github.io/talk/example-talk/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/example-talk/","section":"event","summary":"An example talk using Wowchemy's Markdown slides feature.","tags":[],"title":"Example Talk","type":"event"},{"authors":["Yujin Kim"],"categories":["Join"],"content":"Yujin has joined CSArch Lab since the Fall semester 2023. We hope she will enjoy adventures in computer architecture research. Welcome!!\n","date":1693526400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1693526400,"objectID":"b7cb13f6a0519bdbe54a1419736a1b32","permalink":"https://ku-csarch.github.io/post/join-lab23fa/","publishdate":"2023-09-01T00:00:00Z","relpermalink":"/post/join-lab23fa/","section":"post","summary":"Yujin has joined CSArch Lab. Welcome aboard!!","tags":["Join"],"title":"Yujin has joined CSArch Lab","type":"post"},{"authors":["Jonghyun Jeong","Myung Kuk Yoon","Yunho Oh","Gunjae Koo"],"categories":null,"content":"","date":1691625600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1691625600,"objectID":"b7dffc7faf3edc330dfca62a07cf97cc","permalink":"https://ku-csarch.github.io/publication/gpu_memc_icpp23/","publishdate":"2023-08-10T00:00:00Z","relpermalink":"/publication/gpu_memc_icpp23/","section":"publication","summary":"Long latency of memory operation is a prominent performance bottleneck in graphics processing units (GPUs). The small data cache that must be shared across dozens of warps (a collection of threads) creates significant cache contention and premature data eviction. Prior works have recognized this problem and proposed warp throttling which reduces the number of active warps contending for cache space. In this paper we discover that individual load instructions in a warp exhibit four different types of data locality behavior: (1) data brought by a warp load instruction is used only once, which is classified as streaming data (2) data brought by a warp load is reused multiple times within the same warp, called intra-warp locality (3) data brought by a warp is reused multiple times but across different warps, called inter-warp locality (4) and some data exhibit both a mix of intra- and inter-warp locality. Furthermore, each load instruction exhibits consistently the same locality type across all warps within a GPU kernel. Based on this discovery we argue that cache management must be done using per-load locality type information, rather than applying warp-wide cache management policies. We propose Access Pattern-aware Cache Management (APCM), which dynamically detects the locality type of each load instruction by monitoring the accesses from one exemplary warp. APCM then uses the detected locality type to selectively apply cache bypassing and cache pinning of data based on load locality characterization. Using an extensive set of simulations we show that APCM improves performance of GPUs by 34% for cache sensitive applications while saving 27% of energy consumption over baseline GPU.","tags":["GPU","Memory Controller","Memory Systems"],"title":"Warped-MC: An Efficient Memory Controller Scheme for Massively Parallel Processors","type":"publication"},{"authors":["Jonghyun Jeong"],"categories":["Conference"],"content":"Jonghyun presented his research work regarding an efficient memory controller scheme for GPUs at the International Conference on Parallel Processing 2023 (ICPP 2023). ICPP is one of premier conferences on parallel computing and architecture. Good job, Jonghyun!\n","date":1691539200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1691539200,"objectID":"e9cc64b84b0783557423b0b43c270197","permalink":"https://ku-csarch.github.io/post/present-icpp23/","publishdate":"2023-08-09T00:00:00Z","relpermalink":"/post/present-icpp23/","section":"post","summary":"Jonghyun presented his research on an efficient memory controller scheme for GPUs at the International Conference on Parallel Processing (ICPP) 2023.","tags":["Talk","Conference"],"title":"Jonghyun presented at ICPP 2023","type":"post"},{"authors":["Jonghyun Jeong","Gunjae Koo"],"categories":["Award"],"content":"Our paper entitled “Warped-MC: An Efficient Memory Controller Scheme for Massively Parallel Processors” was awarded the Best Paper Award from the 52nd International Conference on Parallel Processing (ICPP). Big congrats Jonghyun!!\n","date":1691452800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1691452800,"objectID":"c7ef06cf73d23cbdbff02e3bb1c307bf","permalink":"https://ku-csarch.github.io/post/award-icpp23/","publishdate":"2023-08-08T00:00:00Z","relpermalink":"/post/award-icpp23/","section":"post","summary":"Our paper entitled **Warped-MC** was awarded the Best Paper Award from the International Conference on Parallel Processing (ICPP) 2023.","tags":["Award"],"title":"Warped-MC awarded the Best Paper Award from ICPP 2023","type":"post"},{"authors":["Gunjae Koo"],"categories":["Service"],"content":"Prof. Gunjae Koo will be serving as a regular member on the program committee for the 30th IEEE International Symposium on High-Performance Computer Architecture (HPCA 2024. HPCA 2024 will be held in in Edinburgh, Scotland, UK. Please submit your best work!\n","date":1690502400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1690502400,"objectID":"c46effb59f7d429e695f7a534073264e","permalink":"https://ku-csarch.github.io/post/committee-hpca24/","publishdate":"2023-07-28T00:00:00Z","relpermalink":"/post/committee-hpca24/","section":"post","summary":"Prof. Gunjae Koo will be serving on the program committee for HPCA 2024. Please submit your best work!","tags":["Committee","Conference"],"title":"Prof. Gunjae Koo will be serving on the program committee for HPCA 2024","type":"post"},{"authors":["Hyunwoo Moon"],"categories":["Conference (Korea)"],"content":"Hyunwoo presented his research regarding the analysis of embedding cache for recommendation systems at Korea Computer Congress 2023 (KCC 2023) held in Jeju-si, Jeju-do. Our lab members also attended the conference. Good job, Hyunwoo!\n","date":1687219200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1687219200,"objectID":"6b0a84cd5ebeb69bb6288b535fd103ce","permalink":"https://ku-csarch.github.io/post/present-kcc23/","publishdate":"2023-06-20T00:00:00Z","relpermalink":"/post/present-kcc23/","section":"post","summary":"Hyunwoo presented his research regarding the analysis of embedding cache for recommendation systems at Korea Computer Congress (KCC) 2023.","tags":["Talk","Conference (Korea)"],"title":"Hyunwoo presented at KCC 2022","type":"post"},{"authors":["Gunjae Koo","Jonghyun Jeong"],"categories":["Conference"],"content":"One paper was accepted to the 52nd International Conference on Parallel Processing (ICPP 2023). Our research paper proposed Warped-MC, an efficient memory controller scheme for modern GPUs. Warped-MC mitigates the latency divergence observed in a warp that create multiple outstanding memory requests. Hence, Warped-MC can effectively reduce a long-tail of load warp execution time to improve the overall GPU performance.\n","date":1686873600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1686873600,"objectID":"7c84286afbff3f9e56363378081c3298","permalink":"https://ku-csarch.github.io/post/accepted-icpp23/","publishdate":"2023-06-16T00:00:00Z","relpermalink":"/post/accepted-icpp23/","section":"post","summary":"Our paper on an efficient memory controller scheme for GPU was accepted to ICPP 2023. (Congrats Jonghyun!)","tags":["Accepted","ICPP","Conference"],"title":"One paper accepted to ICPP 2023","type":"post"},{"authors":["Hyunwoo Moon","Hunjong Lee"],"categories":["Defense"],"content":"Hyunwoo and Hunjong successfully defended their Master’s theses. Congratulations guys!!\n","date":1686182400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1686182400,"objectID":"24971e8d45da9a74af2dd53bc4ae42f0","permalink":"https://ku-csarch.github.io/post/defense-masters23/","publishdate":"2023-06-08T00:00:00Z","relpermalink":"/post/defense-masters23/","section":"post","summary":"Hyunwoo and Hunjong defended their Master's theses successfully. Congratulations!!","tags":["Defense"],"title":"Hyunwoo and Hunjong defended","type":"post"},{"authors":["Inje Kim"],"categories":["Career"],"content":"Inje has got admission to several universities for doctoral programs. He decided to pursue his Ph.D. degree in the Computer Science \u0026amp; Engineering Department at the University of California, Santa Cruz. Congratulations, Inje!\n","date":1681516800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1681516800,"objectID":"5873e982347814fe997e78c216b464e3","permalink":"https://ku-csarch.github.io/post/career-inje23/","publishdate":"2023-04-15T00:00:00Z","relpermalink":"/post/career-inje23/","section":"post","summary":"Inje has got admission to University of California, Santa Cruz. Congrats Inje!","tags":["Career","Admission"],"title":"Inje has got addmission to UCSC","type":"post"},{"authors":["Minkyu Song","Taeweon Suh","Gunjae Koo"],"categories":null,"content":"","date":1679443200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1679443200,"objectID":"9d1483fee439ffe4e413718db285dc77","permalink":"https://ku-csarch.github.io/publication/sec_attack_access23/","publishdate":"2023-03-22T00:00:00Z","relpermalink":"/publication/sec_attack_access23/","section":"publication","summary":"Cache side-channel attacks have been serious security threats to server computer systems, thus researchers have proposed software-based defense approaches that can detect the security attacks. Profiling-based detectors are lightweight detection solutions that rely on hardware performance counters to identify unique cache performance behaviors by cache side-channel attacks. The detectors typically need to set appropriate criteria to differentiate between attack processes and normal applications. In this paper, we explore the limitations of profiling-based detectors that rely on hardware performance counters. We present an attack scenario, called Vizard, that can bypass the existing profiling-based detectors by manipulating cache performance behaviors of an attack process. Our analysis discloses that cache side-channel attacks include idle periods that can be exploited as attack windows for creating cache events. Vizard generates counterbalancing cache events within the attack windows to hide particular cache performance behaviors of cache side-channel attacks. Our evaluation exhibits that Vizard can effectively bypass profiling-based detectors while maintaining high attack success rates. Our research work represents that attackers can bypass the existing detection approaches by manipulating performance counters.","tags":["Security Attack","Cache Side-Channel Attack","Security Attack Detector"],"title":"Vizard: Passing over Profiling-Based Detection by Manipulating Performance Counters","type":"publication"},{"authors":["Gunjae Koo"],"categories":["Journal"],"content":"One paper was accepted to IEEE Access. Our paper presents an attack scenario, called Vizard, that can bypass the existing profiling-based detectors. The Vizard attack manipulate cache performance behaviors within the allowed attack windows to hide the unique performance behaviors of cache side-channel attacks.\n","date":1678665600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1678665600,"objectID":"36b5871bad456054acc92fa50f7d2218","permalink":"https://ku-csarch.github.io/post/accepted-access23/","publishdate":"2023-03-13T00:00:00Z","relpermalink":"/post/accepted-access23/","section":"post","summary":"A paper on a secure attack scenario that exploits limitations in profiling-based detection appraoches was accepted to IEEE Access. (Congrats Minkyu!)","tags":["Accepted","IEEE Access","Journal"],"title":"One paper accepted to IEEE Access (Journal, SCIE)","type":"post"},{"authors":["Taewoon Kang","Yujin Lee","Jiwon Shin","Geonwoo Choi","Dowon Kwon"],"categories":["Join"],"content":"Taewoon, Yujin, Jiwon, Geonwoo, and Dowon have joined CSArch Lab since the Spring semester 2023. We hope they will enjoy adventures in computer architecture research. Welcome!!\n","date":1677628800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1677628800,"objectID":"61d7bceabcc54c213a794d8e62209765","permalink":"https://ku-csarch.github.io/post/join-lab23sp/","publishdate":"2023-03-01T00:00:00Z","relpermalink":"/post/join-lab23sp/","section":"post","summary":"Taewoon, Yujin, Jiwon, Geonwoo, and Dowon have joined CSArch Lab. Welcome aboard!!","tags":["Join"],"title":"Taewoon, Yujin, Jiwon, Geonwoo, and Dowon have joined CSArch Lab","type":"post"},{"authors":["Jongmin Lee","Seungho Jung","Inje Kim","Boyoung Park","Jonghyun Jeong"],"categories":["Graduate"],"content":"Jongmin, Seungho, Inje, Boyoung, and Jonghyun graduated from Korea University. Jongmin received the Ph.D. degree in computer science and engineering. Seungho, Inje, Boyoung, and Jonghyun received the M.S. degree in computer science and engineering. Boyoung and Jonghyun will be with CSArch Lab to pursue the Ph.D. degree. Congratulations!! Well deserved!\n","date":1677196800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1677196800,"objectID":"3ba1b61750040598f6e9c107eb17f717","permalink":"https://ku-csarch.github.io/post/commence23sp/","publishdate":"2023-02-24T00:00:00Z","relpermalink":"/post/commence23sp/","section":"post","summary":"Jongmin, Seungho, Inje, Boyoung, and Jonghyun graduated from Korea University. Congratulations!!","tags":["Graduate"],"title":"Jongmin, Seungho, Inje, Boyoung, and Jonghyun graduated","type":"post"},{"authors":["Gunjae Koo"],"categories":["Service"],"content":"Prof. Gunjae Koo will be serving on the program committee for the 12th IEEE Non-Volatile Memory Systems and Applications Symposium (NVMSA 2023). NVMSA 2023 will be held on August 30–Septermber 1 in Niigata, Japan. Please submit your best work!\n","date":1676505600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1676505600,"objectID":"335ae474b1af8daf0d7cfcef92989040","permalink":"https://ku-csarch.github.io/post/committee-nvmsa23/","publishdate":"2023-02-16T00:00:00Z","relpermalink":"/post/committee-nvmsa23/","section":"post","summary":"Prof. Gunjae Koo will be serving on the program committee for NVMSA 2023. Please submit your best work!","tags":["Committee","Conference"],"title":"Prof. Gunjae Koo will be serving on the program committee for NVMSA 2023","type":"post"},{"authors":["Gunjae Koo","Jonghyun Jeong","Boyoung Park","Inje Kim","Hunjong Lee","Hyunwoo Moon","Yewon Hwang","Jaewon Seo"],"categories":["Training","Service"],"content":"CSArch Lab members attended KIISE Computer System Society Conference 2023 (CSC 2023) held in Pyeongchang, Gangwon-do. Our lab members had a great time as the great researchers on computer system research fields presented keynotes and their research work during the conference. Jonghyun and Boyoung presented their research work during the Student Poster Session. Prof. Gunjae Koo served on the organizing committee for CSC 2023.\n","date":1675641600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1675641600,"objectID":"3c220b6de9447a5a32484f7487294182","permalink":"https://ku-csarch.github.io/post/attend-csc23/","publishdate":"2023-02-06T00:00:00Z","relpermalink":"/post/attend-csc23/","section":"post","summary":"CSArch Lab members attended KIISE Computer System Society Conference (CSC) 2023.","tags":["Training","Conference (Korea)"],"title":"CSArch Lab members attended CSC 2023","type":"post"},{"authors":["Boyoung Park","Gunjae Koo"],"categories":null,"content":"","date":1671667200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1671667200,"objectID":"01ec48d6b109de7c618a80c1ac678d1d","permalink":"https://ku-csarch.github.io/publication/ssd_genome_ksc22/","publishdate":"2022-12-22T00:00:00Z","relpermalink":"/publication/ssd_genome_ksc22/","section":"publication","summary":"차세대 시퀀싱 기술의 개발로 유전체 데이터 크기가 매우 빠르게 증가하고 있다. 이에 따라 염기 서열 정렬이 새로운 빅데이터 워크로드로서 소프트웨어, 하드웨어적 가속 연구가 활발히 진행되고 있다. 본 연구에서는 이전의 매핑 프로그램보다 최소 2배 이상 빠른 Minimap2 프로그램을 분석했다. 그 결과, 병렬 처리 성능이 쓰레드 수에 비례할 정도로 효과적이나 메모리 데이터 베이스 공간의 한계로 메모리 용량이 충분하지 않을 때 최대 92.2배로 I/O 접근이 크게 늘어남을 확인했다. 그러므로 처리량 향상을 위해 개선된 시스템에서는 메모리가 부족하지 않게 수백 GB의 유전체 데이터를 관리할 수 있어야한다.","tags":["SSD","Storage","Genome Analysis"],"title":"Performance Analysis of the Modern Genome Alignment Application","type":"publication"},{"authors":["Boyoung Park","Jongmin Lee"],"categories":["Conference (Korea)"],"content":"Boyoung and Jongmin presented their research work at Korea Software Congress 2022 (KSC 2022) held in Jeju-si, Jeju-do. Boyoung presented her research on performance analysis of a genome alignment application. Jongmin presented his research on low-overhead secure architectures at a Ph.D. forum of KSC 2022. Our lab memebers also attended the conference to have a great time. Good job, guys!\n","date":1671580800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1671580800,"objectID":"e6be6cd26b3f20dbb6ae4619182c9d01","permalink":"https://ku-csarch.github.io/post/present-ksc22/","publishdate":"2022-12-21T00:00:00Z","relpermalink":"/post/present-ksc22/","section":"post","summary":"Boyoung and Jongmin presented their research work at Korea Software Congress (KSC) 2022.","tags":["Talk","Conference (Korea)"],"title":"Boyoung and Jongmin presented at KSC 2022","type":"post"},{"authors":["Gunjae Koo"],"categories":["Service"],"content":"Prof. Gunjae Koo will be serving on the program committee for the 15th Workshop on the General Purpose Processing Using GPU (GPGPU 2023). GPGPU 2023 will be held in conjunction with HPCA 2023 in Montreal, QC, Canada. Please submit your best work!\n","date":1670716800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1670716800,"objectID":"e93224e9310e5b25ac5064e2f2617328","permalink":"https://ku-csarch.github.io/post/committee-gpgpu23/","publishdate":"2022-12-11T00:00:00Z","relpermalink":"/post/committee-gpgpu23/","section":"post","summary":"Prof. Gunjae Koo will be serving on the program committee for GPGPU 2023. Please submit your best work!","tags":["Committee","Workshop"],"title":"Prof. Gunjae Koo will be serving on the program committee for GPGPU 2023","type":"post"},{"authors":["Boyoung Park","Jonghyun Jeong","Inje Kim","Seungho Jung"],"categories":["Defense"],"content":"Boyoung, Jonghyun, Inje, and Seungho successfully defended their Master’s theses. Congratulations guys!!\n","date":1670284800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1670284800,"objectID":"bba282bce0125a18a58c33904ebc969f","permalink":"https://ku-csarch.github.io/post/defense-masters22/","publishdate":"2022-12-06T00:00:00Z","relpermalink":"/post/defense-masters22/","section":"post","summary":"Boyoung, Jonghyun, Inje, and Seungho defended their Master's theses successfully. Congratulations!!","tags":["Defense"],"title":"Boyoung, Jonghyun, Inje, and Seungho defended","type":"post"},{"authors":["Jongmin Lee"],"categories":["Defense"],"content":"Jongmin successfully defended his thesis entitled “Low-Overhead Architectural Defense Approaches against Security Attacks”. He is now the newest (and the first) member of CSArch’s PhD alumni. Big congratulations Dr. Lee!\n","date":1669939200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1669939200,"objectID":"8b7cf364f2db61bff086d6b98bc6218c","permalink":"https://ku-csarch.github.io/post/defense-jongmin/","publishdate":"2022-12-02T00:00:00Z","relpermalink":"/post/defense-jongmin/","section":"post","summary":"Jongmin defended his thesis successfully. Big congrats Jongmin!","tags":["Defense"],"title":"Dr. Lee, newly minted Ph.D.","type":"post"},{"authors":["Jonghyun Jeong","Inje Kim","Jaewon Seo"],"categories":["Training"],"content":"Jonghyun, Inje, and Jaewon attended an oversea training program supported by the Convergence Security Core Talent Training Program. They visited VDE and BOSCH Cybercompare to present internship proposals regarding computer security policies and solutions.\n","date":1667433600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1667433600,"objectID":"3c662f13dd546bc15f4899c763547965","permalink":"https://ku-csarch.github.io/post/training-germany22/","publishdate":"2022-11-03T00:00:00Z","relpermalink":"/post/training-germany22/","section":"post","summary":"Jonghyun, Inje, and Jaewon attended an oversea training program in Germany","tags":["Training"],"title":"Jonghyun, Inje, and Jaewon attended a training program in Germany","type":"post"},{"authors":["Inje Kim","Jonghyun Jeong","Yunho Oh","Myung Kuk Yoon","Gunjae Koo"],"categories":null,"content":"","date":1666310400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1666310400,"objectID":"cb4fbc9120e0d9f42eb8955d30a9d0ed","permalink":"https://ku-csarch.github.io/publication/gnn_load_access22/","publishdate":"2022-10-21T00:00:00Z","relpermalink":"/publication/gnn_load_access22/","section":"publication","summary":"Graph convolutional neural networks (GCNs) are emerging neural networks for graph structures that include large features associated with each vertex. The operations of GCN can be divided into two phases - aggregation and combination. While the combination just performs matrix multiplications using trained weights and aggregated features, the aggregation phase requires graph traversal to collect features from adjacent vertices. Even though neural network applications rely on GPU's massively parallel processing, GCN aggregation kernels exhibit rather low performance since graph processing using compressed graph structures provokes frequent irregular accesses in GPUs. In order to investigate the performance hurdles of GCN aggregation on GPU, we perform an in-depth analysis of the aggregation kernels using real GPU hardware and a cycle-accurate GPU simulator. We first analyze the characteristics of the popular graph datasets used for GCN studies. We reveal the fractions of non-zero elements in feature vectors are diverse among datasets. Based on the observation, we build two types of aggregation kernels that handle uncompressed and compressed feature vectors. Our evaluation exhibits the performance of aggregation can be significantly influenced by kernel design approaches and feature density. We also analyze the individual loads that access the data arrays of the aggregation kernels to specify critical loads. Our analysis reveals the performance of GPU memory hierarchy is influenced by access patterns and feature size of graph datasets. Based on our observations we discuss possible kernel design approaches and architectural ideas that can improve the performance of GCN aggregation.","tags":["Graph Neural Networks","GCN","Aggregation","GPU","Characteristics"],"title":"Analyzing GCN Aggregation on GPU","type":"publication"},{"authors":["Gunjae Koo","Jongmin Lee","Seungho Jung","Inje Kim","Jonghyun Jeong"],"categories":["Journal"],"content":"Two papers were accepted to IEEE Access. One paper proposes GhostLeg, a low-overhead architectural defense approach against correlation-based GPU security attacks. GhostLeg selectively applies secure executions for load warps to minimize performance overhead induced by concealing memory coalescing. Another paper presents detailed characteristics of GCN aggregation kernels on GPU via an in-depth analysis using real GPU hardware and a cycle-accurate GPU simulator.\n","date":1666310400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1666310400,"objectID":"c78f1e89c2efeca996180f335fa2d08d","permalink":"https://ku-csarch.github.io/post/accepted-access22/","publishdate":"2022-10-21T00:00:00Z","relpermalink":"/post/accepted-access22/","section":"post","summary":"A paper on low-overhead secure GPU architecture against correlation-based timing attacks was accepted to IEEE Access. (Congrats Jongmin and Seungho!) A paper on characteristics of GCN aggregation kernels on GPU was also accepted to IEEE Access. (Congrats Inje and Jonghyun!)","tags":["Accepted","IEEE Access","Journal"],"title":"Two papers accepted to IEEE Access (Journal, SCIE)","type":"post"},{"authors":["Jongmin Lee","Seungho Jung","Taeweon Suh","Yunho Oh","Myung Kuk Yoon","Gunjae Koo"],"categories":null,"content":"","date":1665964800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1665964800,"objectID":"6ca22b6972d2bc7125c1b098eb207cde","permalink":"https://ku-csarch.github.io/publication/gpu_sec_access22/","publishdate":"2022-10-17T00:00:00Z","relpermalink":"/publication/gpu_sec_access22/","section":"publication","summary":"Architectural considerations for secure executions are getting more critical for GPU since popular security applications and libraries have been ported to a GPU domain to rely on GPU’s massively parallel computations. Recent studies disclosed the security attack models that exploit GPU’s architectural vulnerabilities to leak the secret keys of AES. The attack models exploit the high correlations between the execution time of a kernel and the number of memory requests generated from memory coalescing. Thus the prior architectural defenses provide secure executions by randomizing or restricting the memory coalescing from load warps. However, those defense approaches result in significant performance overhead since memory coalescing is an essential feature for improving the performance of GPU. In this paper, we propose GhostLeg, an efficient architectural defense approach against correlation-based GPU security attacks. GhostLeg selectively applies secure executions for load warps to minimize performance overhead induced by concealing memory coalescing behavior. Our analysis of AES reveals that only the load warps whose index addresses are influenced by secret keys are vulnerable to security attacks. In order to minimize the performance overhead by secure executions, GhostLeg pinpoints the load warps that require secure executions based on the class of a source register. The secure flag assigned to each register can be set by propagation from non-deterministic user data (GhostLeg-ND) or a specific directive marked by programmers (GhostLeg-Key). Our evaluation shows that GhostLeg guarantees secure executions against the correlation-based attacks and GhostLeg-ND exhibits 54.7% higher performance compared to the state-of-the-art GPU defense solution.","tags":["GPU","Secure Architecture","Coalescing"],"title":"GhostLeg: Selective Memory Coalescing for Secure GPU Architecture","type":"publication"},{"authors":["Jongmin Lee"],"categories":["Training"],"content":"Jongmin attended the IEEE/ACM International Symposium on Microarchitecture 2022 (MICRO 2022) held in Chicago, Illinois, USA.\n","date":1664582400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1664582400,"objectID":"0eb75f62e5951768a2ed1cd730842d48","permalink":"https://ku-csarch.github.io/post/attend-micro22/","publishdate":"2022-10-01T00:00:00Z","relpermalink":"/post/attend-micro22/","section":"post","summary":"Jongmin attended the IEEE/ACM International Symposium on Microarchitecture (MICRO) 2022.","tags":["Training","Conference"],"title":"Jongmin attended MICRO 2022","type":"post"},{"authors":["Jaewon Seo","Yewon Hwang"],"categories":["Join"],"content":"Jaewon and Yewon have joined CSArch Lab since the Fall semester 2022. We hope they will enjoy adventures in computer architecture research. Welcome!!\n","date":1661990400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1661990400,"objectID":"69809ef8eef6b48c15471c18d797c8e3","permalink":"https://ku-csarch.github.io/post/join-lab22fa/","publishdate":"2022-09-01T00:00:00Z","relpermalink":"/post/join-lab22fa/","section":"post","summary":"Jaewon and Yewon have joined CSArch Lab. Welcome aboard!!","tags":["Join"],"title":"Jaewon and Yewon have joined CSArch Lab","type":"post"},{"authors":["Jongmin Lee"],"categories":["Award"],"content":"Jongmin received an excellet research paper award from Korea University for the research paper entitled “CacheRewinder: Revoking Speculative Cache Updates Exploiting Write-Back Buffer” published in the proceedings of 2022 Design, Automation \u0026amp; Test in Europe Conference \u0026amp; Exhibition (DATE). Congrats Jongmin!\n","date":1661385600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1661385600,"objectID":"d2d90b8bb262a6e44f5086f54f77b71e","permalink":"https://ku-csarch.github.io/post/award-ku22/","publishdate":"2022-08-25T00:00:00Z","relpermalink":"/post/award-ku22/","section":"post","summary":"Jongmin received an excellent research paper award from Korea University. Congrats!!","tags":["Award"],"title":"Jongmin received an excellent research paper award from Korea University","type":"post"},{"authors":["Gunjae Koo","Hunjong Lee"],"categories":["Conference (Korea)"],"content":"Hunjong presented his research on the characteristics of GCN kernels on accelerator architectures at Korea Computer Congress 2022 (KCC 2022) held in Seoguipo-si, Jeju-do. Our lab members also attended the conference. Good job, Hunjong!\n","date":1656547200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1656547200,"objectID":"af4ba19745a40e20c0c5ba6f504b6c62","permalink":"https://ku-csarch.github.io/post/present-kcc22/","publishdate":"2022-06-30T00:00:00Z","relpermalink":"/post/present-kcc22/","section":"post","summary":"Hunjong presented his research on the characteristics of GCN kernels on accelerator architectures at Korea Computer Congress (KCC) 2022.","tags":["Talk","Conference (Korea)"],"title":"Hunjong presented at KCC 2022","type":"post"},{"authors":["Hunjong Lee","Gunjae Koo"],"categories":null,"content":"","date":1656460800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1656460800,"objectID":"805bbc8bb3137244229cd93fa0991122","permalink":"https://ku-csarch.github.io/publication/gnn_accel_kcc22/","publishdate":"2022-06-29T00:00:00Z","relpermalink":"/publication/gnn_accel_kcc22/","section":"publication","summary":"Graph neural networks의 연산 과정은 높은 희소성을 갖는 행렬 연산을 포함하고 있다. 그러므로, GNN 처리를 기존의 조밀 행렬 및 낮은 희소성을 가지는 행렬 연산에 특화된 가속기에서 수행할 경우 매우 낮은 효율을 보일 것으로 예상할 수 있다. 이 논문에서는 GNN의 대표적인 응용 방법인 GCN 커널을 행렬 연산 가속기 구조 중의 하나인 TPU와 SIGMA에서 수행시키면서 GCN 커널이 보여주는 성능 저하 요소를 분석하였다. 분석 결과 기존의 가속기 구조에서는 매우 높은 희소성을 가지는 행렬 연산이 낮은 효율성은 보여주는 것을 밝혔으며 이는 데이터의 이동 및 zero 값에 따른 PE의 낮은 utilization에 의한 것임을 밝혀내었다.","tags":["GNN","Profiling","Accelerator"],"title":"Performance Analysis of Graph Convolutional Networks on Accelerator Architectures","type":"publication"},{"authors":["Gunjae Koo"],"categories":["Service"],"content":"Prof. Gunjae Koo will be serving on the program committee for the 11th IEEE Non-Volatile Memory Systems and Applications Symposium (NVMSA 2022). NVMSA 2022 will be held on August 23–25 in Taipei, Taiwan. Please submit your best work!\n","date":1649116800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1649116800,"objectID":"105b2a0d0e63badcfbe69d300253a23d","permalink":"https://ku-csarch.github.io/post/committee-nvmsa22/","publishdate":"2022-04-05T00:00:00Z","relpermalink":"/post/committee-nvmsa22/","section":"post","summary":"Prof. Gunjae Koo will be serving on the program committee for NVMSA 2022. Please submit your best work!","tags":["Committee","Conference"],"title":"Prof. Gunjae Koo will be serving on the program committee for NVMSA 2022","type":"post"},{"authors":["Jongmin Lee","Junyeon Lee","Taeweon Suh","Gunjae Koo"],"categories":null,"content":"","date":1647561600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1647561600,"objectID":"91b47f73ea04fe266ac17a8f8d3c8103","permalink":"https://ku-csarch.github.io/publication/sec_victim_date22/","publishdate":"2022-03-18T00:00:00Z","relpermalink":"/publication/sec_victim_date22/","section":"publication","summary":"Transient execution attacks are critical security threats since those attacks exploit speculative execution which is an essential architectural solution that can improve the performance of out-of-order processors significantly. Such attacks change cache state by accessing secret data during speculative executions, then the attackers leak the secret information exploiting cache timing side-channels. Even though software patches against transient execution attacks have been proposed, the software solutions significantly slow down the performance of a system. In this paper, we propose CacheRewinder, an efficient hardware-based defense mechanism against transient execution attacks. CacheRewinder prevents leakage of secret information by revoking the cache updates done by speculative executions. To restore the cache state efficiently, CacheRewinder exploits the underutilized write-back buffer space as the temporary storage for victimized cache blocks that are evicted during speculative executions. Hence when speculation fails CacheRewinder can quickly restore the cache state using the evicted cache blocks held in the write-back buffer. Our evaluation exhibits that CacheRewinder can effectively defend the transient execution attacks. The performance overhead by CacheRewinder is only 0.6%, which is negligible compared to the unprotected baseline processor. CacheRewinder also requires minimal storage cost since it exploits unused write-back buffer entries as storage for evicted cache blocks.","tags":["Security","Secure Architecture","Transient Execution Attack","Cache Side-Channel"],"title":"CacheRewinder: Revoking Speculative Cache Updates Exploiting Write-Back Buffer","type":"publication"},{"authors":["Jongmin Lee"],"categories":["Conference"],"content":"Jongmin presented his research work regarding an efficient architectural defense mechanism against transient execution attacks at the Design, Automation and Test in Europe Conference 2022 (DATE 2022). DATE is one of top-tier conferences on EDA and VLSI design. Good job, Jongmin!\n","date":1647561600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1647561600,"objectID":"59fe746e588a9c9c1b27c85e3646e64e","permalink":"https://ku-csarch.github.io/post/present-date22/","publishdate":"2022-03-18T00:00:00Z","relpermalink":"/post/present-date22/","section":"post","summary":"Jongmin presented his research on secure processor architecture agains transient execution attacks at the Design, Automation and Test in Europe Conference (DATE) 2022.","tags":["Talk","Conference"],"title":"Jongmin presented at DATE 2022","type":"post"},{"authors":["Young Seo Lee","Gunjae Koo","Young-Ho Gong","Sung Woo Chung"],"categories":null,"content":"","date":1647561600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1647561600,"objectID":"c2cdbdff88e0f63cb5e0e3586eaa7b40","permalink":"https://ku-csarch.github.io/publication/dram_ecc_date22/","publishdate":"2022-03-18T00:00:00Z","relpermalink":"/publication/dram_ecc_date22/","section":"publication","summary":"As DRAM process technology scales down and DRAM density continues to grow, DRAM errors have become a primary concern in modern data centers. Typically, data centers have adopted memory systems with a single error correction double error detection (SECDED) code. However, the SECDED code is not sufficient to satisfy DRAM reliability demands as memory systems get more vulnerable. Though the servers in data centers employ strong ECC schemes such as Chipkill, such ECC schemes lead to substantial performance and/or storage overhead. In this paper, we propose Stealth ECC, a cost-effective memory protection scheme providing stronger error correctability than the conventional SECDED code, with negligible performance overhead and without storage overhead. Depending on the data-width (either narrow-width or full-width), Stealth ECC adaptively selects ECC schemes. For narrow-width values, Stealth ECC provides multi-bit error correctability by storing more parity bits in MSB side, instead of zeros. Furthermore, with bitwise interleaved data placement between x4 DRAM chips, Stealth ECC is robust to a single DRAM chip error for narrow-width values. On the other hand, for full-width values, Stealth ECC adopts the SECDED code, which maintains DRAM reliability comparable to the conventional SECDED code. As a result, thanks to the reliability improvement of narrow-width values, Stealth ECC enhances overall DRAM reliability, while incurring negligible performance overhead as well as no storage overhead. Our simulation results show that Stealth ECC reduces the probability of system failure (caused by DRAM errors) by 47.9%, on average, with only 0.9% performance overhead compared to the conventional SECDED code.","tags":["DRAM","Error Correction Code","Reliability","Chip Error Resilience"],"title":"Stealth ECC: A Data-Width Aware Adaptive ECC Scheme for DRAM Error Resilience","type":"publication"},{"authors":["Gunjae Koo","Yunho Oh","Hung-Wei Tseng","Won Woo Ro","Murali Annavaram"],"categories":null,"content":"","date":1645747200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1645747200,"objectID":"cd21da754e61b09c8b397146076514c0","permalink":"https://ku-csarch.github.io/publication/ssd_index_tc22/","publishdate":"2022-02-25T00:00:00Z","relpermalink":"/publication/ssd_index_tc22/","section":"publication","summary":"Flash memory technologies rely on the flash translation layer (FTL) to manage no in-place update and garbage collection. Current FTL management schemes do not exploit the semantics of the accessed data. In this paper, we explore how semantic knowledge can be exploited to build and maintain indexes for stored data automatically. Data indexing is a critical enabler to accelerate many database applications and big data analytics. Unlike traditional per-table or per-file indexes that are managed separately from the data, we propose to maintain indexes on a per-flash page basis. Our approach, called FLash IndeXeR (FLIXR), builds and maintains page-level indexes whenever a page is written into the flash. FLIXR updates the indexes alongside any data updates at page granularity. The cost of the index update is hidden in the page write delays. FLIXR stores index data for each page within the FTL entry associated with that page, thereby piggybacking index access on a page access request. FLIXR accesses the index data in each FTL entry to determine whether the associated page stores data with a given key. FLIXR achieves 52.6% performance improvement for TPC-C and TPC-H benchmarks, compared to the conventional host-side indexing mechanism.","tags":["SSD","Database Index","In-Storage Processing"],"title":"FLIXR: Embedding Index into Flash Translation Layer in SSDs","type":"publication"},{"authors":["Gunjae Koo"],"categories":["Journal"],"content":"One paper was accepted to IEEE Transactions on Computers. Our paper proposes FLIXR, an efficient in-storage indexing mechanism in SSDs. FLIXR builds and maintains the page-level indexes exploiting the SSD’s native page translation structures. FLIXR automatically creates and updates new per-page indexes while new data is written to flash memory pages. FLIXR’s in-storage indexes are efficiently maintained in SSD’s flash translation layer alongside with page translation structures. Hence FLIXR can effectively reduce host processor’s heavy burdens for creating and maintaining index structures of large database structures.\n","date":1644710400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1644710400,"objectID":"7f690ed707b5850cb489e5ffc7812e9e","permalink":"https://ku-csarch.github.io/post/accepted-tc22/","publishdate":"2022-02-13T00:00:00Z","relpermalink":"/post/accepted-tc22/","section":"post","summary":"Our paper on an in-storage indexing mechanism was accepted to IEEE Transactions on Computers.","tags":["Accepted","IEEE TC","Journal"],"title":"One paper accepted to IEEE Transactions on Computers (Journal, SCIE)","type":"post"},{"authors":["Gunjae Koo","Jongmin Lee","Seungho Jung","Jonghyun Jeong","Boyoung Park","Hunjong Lee","Hyunwoo Moon"],"categories":["Training","Service"],"content":"CSArch Lab members attended KIISE Computer System Society Conference 2022 (CSC 2022) held in Pyeongchang, Gangwon-do. Our lab members had a great time as the great researchers on computer system research fields presented keynotes and their research work during the conference. Prof. Gunjae Koo served on the organizing committee for CSC 2022. Our lab members also helped organizing the conference.\n","date":1644192000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1644192000,"objectID":"cb432a436ead4723cd66c7d79219fc98","permalink":"https://ku-csarch.github.io/post/attend-csc22/","publishdate":"2022-02-07T00:00:00Z","relpermalink":"/post/attend-csc22/","section":"post","summary":"CSArch Lab members attended KIISE Computer System Society Conference (CSC) 2022.","tags":["Training","Conference (Korea)"],"title":"CSArch Lab members attended CSC 2022","type":"post"},{"authors":["Gunjae Koo","Boyoung Park","Hyunwoo Moon"],"categories":["Training","Service"],"content":"Boyoung and Hyunwoo attended Linux Kernel Camp 2022 (LKC 2022) to take lectures regarding memory management and file systems. They also explored memory management practices and file system implementations through the provided lab sessions. LKC 2022 provided great learning opportunities for those who work on computer system research. Prof. Gunjae Koo served on the organizing committee for LKC 2022.\n","date":1642636800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1642636800,"objectID":"9fbbbc872e75227d302fbfcbd02cd728","permalink":"https://ku-csarch.github.io/post/attend-lkc22/","publishdate":"2022-01-20T00:00:00Z","relpermalink":"/post/attend-lkc22/","section":"post","summary":"Boyoung and Hyunwoo attended Linux Kernel Camp (LKC) 2022.","tags":["Training","Lecture"],"title":"Boyoung and Hyunwoo attended LKC 2022","type":"post"},{"authors":["Gunjae Koo","Jongmin Lee"],"categories":["Conference"],"content":"Jongmin presented his research work regarding the new cache side-channel attack mechanism that exploits the vulnerabilities in the undo-based archtiectural defense solutions at the 36th International Conference on Information Networking (ICOIN 2022) held in Jeju-si, Jeju-do, South Kroea. Good job, Jongmin!\n","date":1641945600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1641945600,"objectID":"b0207e8c7b7e8d021519620a47809061","permalink":"https://ku-csarch.github.io/post/present-icoin22/","publishdate":"2022-01-12T00:00:00Z","relpermalink":"/post/present-icoin22/","section":"post","summary":"Jongmin presented his research on security attacks on the modern processors at the 36th International Conference on Information Networking (ICOIN) 2022.","tags":["Talk","Conference"],"title":"Jongmin presented at ICOIN 2022","type":"post"},{"authors":["Jongmin Lee","Gunjae Koo"],"categories":null,"content":"","date":1641945600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1641945600,"objectID":"d316b6addd90be608ee065842b31d648","permalink":"https://ku-csarch.github.io/publication/sec_attack_icoin22/","publishdate":"2021-01-12T00:00:00Z","relpermalink":"/publication/sec_attack_icoin22/","section":"publication","summary":"Transient execution attacks have been severe security threats since such attacks exploit architectural vulnerabilities in out-of-order processors. Researchers proposed several architectural solutions to defend against transient execution attacks. By restoring the victim blocks stored temporarily in a restore buffer, the undo-based approaches can revoke the cache state changed by speculative loads. Thus it is known that the undo-based defense mechanisms can protect processors from transient execution attacks.In this paper, we reveal the undo-based protection scheme is still vulnerable to the elaborated Prime+Probe type attacks. Under the undo-based protection, the victim blocks by the speculative loads are stored in the restore buffer that has limited resources. Thus if the restore buffer is full, part of the victim blocks in the restore buffer can be evicted from the restore buffer. Then the cache state cannot be restored since the processor cannot find the victim blocks required for restoring the cache state. We design a restore buffer overflow attack that can leak secret data even if the processor is protected under the undo-based scheme. We evaluate the attack mechanism using the architectural simulator. Our evaluation exhibits that the attack can leak part of secret data successfully.","tags":["Security","Secure Architecture","Transient Execution Attack","Cache Side-Channel"],"title":"Restore Buffer Overflow Attacks: Breaking Undo-Based Defense Schemes","type":"publication"},{"authors":["Seungho Jung","Myung Kuk Yoon","Gunjae Koo"],"categories":null,"content":"","date":1639958400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1639958400,"objectID":"0491d9091d005e20b7832e401100ece7","permalink":"https://ku-csarch.github.io/publication/gpu_side_ksc21/","publishdate":"2021-12-20T00:00:00Z","relpermalink":"/publication/gpu_side_ksc21/","section":"publication","summary":"최근 연구에서 GPU에서 수행하는 AES와 RSA와 같은 암호 알고리즘에서 GPU의 고유한 메모리 접합 구조에 따른 메모리 접근 시간의 차이를 이용하여 공격자가 암호키를 복원할 수 있음이 밝혀졌다. 이는 GPU 캐시 구조 및 메모리 접합 방식에 따라 공격자가 역연산을 통해 GPU의 메모리 요청 개수와 이에 따른 암호화 커널의 수행시간의 관계를 쉽게 알아낼 수 있기 때문이다. 본 연구에서는 변환 테이블을 사용하는 암호화 알고리즘에서 GPU의 메모리 접합 크기 및 변환 테이블의 접근 시간에 따른 GPU의 메모리 접근 시간 부채널의 특성을 GPU 구조 시뮬레이터를 통해서 분석하였다. 이러한 분석을 통하여 메모리 접합 크기 및 접근 시간에 따라 GPU 메모리의 부채널 취약성이 변화함을 밝혀냈으며 이러한 GPU 메모리 부채널의 취약점을 dummy 메모리 요청의 추가로 보완할 수 있음을 보여주었다.","tags":["GPU","Security","Side-Channel"],"title":"Analyzing Characteristics of Memory Timing Side-Channels in GPU","type":"publication"},{"authors":["Jonghyun Jeong","Yunho Oh","Gunjae Koo"],"categories":null,"content":"","date":1639958400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1639958400,"objectID":"91ae630b939543972989e9bd17e0f3cc","permalink":"https://ku-csarch.github.io/publication/gpu_cache_ksc21/","publishdate":"2021-12-20T00:00:00Z","relpermalink":"/publication/gpu_cache_ksc21/","section":"publication","summary":"Graphics processing unit (GPU)는 그래픽 어플리케이션의 처리 뿐만 아니라 최근 machine learning, big data analytics 등의 대규모 병렬처리를 요구하는 어플리케이션의 처리에 널리 사용되고 있다. GPU는 많은 수의 쓰레드를 동시에 실행하는 병렬처리 구조를 가지고 있다. 이 때문에 많은 메모리 요청이 단시간 내에 발생되어 메모리 계층구조의 자원이 소진되고 데이터 캐시가 비효율적으로 사용되는 문제가 있었다. 최신 GPU 아키텍처에서는 이러한 문제를 해결하기 위해 streaming cache라고 불리는 새로운 캐시 구조를 적용하여 데이터 캐시의 성능 저하 요소를 줄였다. 본 연구에서는 최신 GPU 시뮬레이터를 사용하여 streaming cache의 성능을 기존 캐시와 자세히 비교하여 streaming cache의 특성을 밝히고 있다. 본 연구에서는 streaming cache가 데이터 캐시의 congestion은 해결하지만 memory congestion이 interconnection network 단으로 옮겨갈 수 있음을 밝혀냈다. 본 연구를 통하여 streaming cache가 최신 GPU 메모리 시스템에서 미치는 영향을 분석하여 최신 GPU 아키텍처의 메모리 시스템에서 발생할 수 있는 성능 문제점들에 대해서 제시한다.","tags":["GPU","Cache","Characteristics"],"title":"Analyzing Data Cache Performance of Modern GPU Architecture","type":"publication"},{"authors":["Inje Kim","Gunjae Koo"],"categories":null,"content":"","date":1639958400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1639958400,"objectID":"10e1e328f8f3d8c5c84ee81b359b403b","permalink":"https://ku-csarch.github.io/publication/gnn_profile_ksc21/","publishdate":"2021-12-20T00:00:00Z","relpermalink":"/publication/gnn_profile_ksc21/","section":"publication","summary":"Graph Convolutional Neural Network (GCN)은 그래프 구조를 이용한 인공 신경망 중의 하나로 소셜 네트워크 분석 및 소비자 성향 분석 등 여러 응용 분야에 이용될 수 있다. GCN 커널은 크게 aggregation 과 combination 의 두 종류로 나눌 수 있다. Combination 은 일반 행렬 연산과 유사하여 GPU 에서 높은 성능을 낼 수 있다. 하지만 aggregation 커널은 불규칙적인 메모리 접근을 유발하는 간접 메모리접근을 많이 포함하고 있어서 GPU 구조에 적합하지 않다. 이러한 문제점을 다루기 위해 여러 가속기 연구에서는 aggregation 커널을 최적화하고 있지만 그래프 구조의 희소성에만 집중하고 있다. 이번 연구에서는 그래프 특성 벡터의 밀집도에 따른 GCN 커널의 성능 분석을 진행하여 특성 벡터 또한 압축된 희소행렬방식으로 처리하였을 때, 2 중 간접주소 접근이 발생함에도 불구하고 sparse feature 에서 더 잘 동작하는 것을 확인했다. 또한 이번 연구에서 GCN 커널의 특성을 분석하여 GCN 커널을 GPU 에서 실행할 때의 성능 저하 요소를 밝히고 커널의 수행 시간을 줄일 수 있는 방법을 제시하고자 한다.","tags":["GNN","Profiling","GPU"],"title":"Analyzing the Performance of GCN Inferences with respect to Sparsity of Graph Features","type":"publication"},{"authors":["Gunjae Koo","Inje Kim","Jonghyun Jeong","Seungho Jung"],"categories":["Conference (Korea)"],"content":"Inje, Jonghyun, and Seungho presented their research work at Korea Software Congress 2021 (KSC 2021) held in Pyeongchang-gun, Gangwon-do. Inje presented his research on GCN inference performance with respect to graph features. Jonghyun presented his research on data cache of modern GPU architecture. Seungho presented his research on characteristics of GPU memory side-channels. Our lab members also attended the conference to have a great time. Good job, guys!\n","date":1639958400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1639958400,"objectID":"92b2e4082405e155352e59fa001c74a1","permalink":"https://ku-csarch.github.io/post/present-ksc21/","publishdate":"2021-12-20T00:00:00Z","relpermalink":"/post/present-ksc21/","section":"post","summary":"Inje, Jonghyun, and Seungho presented their research work at Korea Software Congress (KSC) 2021.","tags":["Talk","Conference (Korea)"],"title":"Inje, Jonghyun, and Seungho presented at KSC 2021","type":"post"},{"authors":["Gunjae Koo"],"categories":["Service"],"content":"Prof. Gunjae Koo will be serving on the program committee for the 14th Workshop on the General Purpose Processing Using GPU (GPGPU 2022). GPGPU 2022 will be held in conjunction with HPCA 2022 in Seoul, South Korea. Please submit your best work!\n","date":1639958400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1639958400,"objectID":"cb8cd728fdf77d32a92fcdd0f79c8088","permalink":"https://ku-csarch.github.io/post/committee-gpgpu22/","publishdate":"2021-12-20T00:00:00Z","relpermalink":"/post/committee-gpgpu22/","section":"post","summary":"Prof. Gunjae Koo will be serving on the program committee for GPGPU 2022. Please submit your best work!","tags":["Committee","Workshop"],"title":"Prof. Gunjae Koo will be serving on the program committee for GPGPU 2022","type":"post"},{"authors":["Gunjae Koo","Jongmin Lee","Junyeon Lee","Taeweon Suh"],"categories":null,"content":"","date":1639526400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1639526400,"objectID":"bf4a12e28a37496e56051acdc721ec06","permalink":"https://ku-csarch.github.io/publication/sec_victim_patent21/","publishdate":"2021-12-15T00:00:00Z","relpermalink":"/publication/sec_victim_patent21/","section":"publication","summary":"","tags":["Security","Secure Architecture"],"title":"Processor and Operation Thereof to Revoke Cache Memory States Utilizing Write-Back Buffer","type":"publication"},{"authors":["Gunjae Koo","Jongmin Lee"],"categories":["Workshop"],"content":"One paper was accepted to the Workshop on Information System Security (WISS) which will be held in conjunction with the International Conference on Information Networking (ICOIN) 2022. Our work reveals the undo-based protection schemes are still vulnerable to the modified Prime+Probe type attack that makes the restore buffer overflowed. Using the proposed restore buffer overflow attack approach, we reveal the attack can leak part of secret data successfully even though the processor is protected by the undo-based defense scheme.\n","date":1638835200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1638835200,"objectID":"6160fedfc62d3d686b6fd793e3e8898d","permalink":"https://ku-csarch.github.io/post/accepted-icoin22/","publishdate":"2021-12-07T00:00:00Z","relpermalink":"/post/accepted-icoin22/","section":"post","summary":"Our paper on architectural vulnerability in undo-type defense mechanisms was accepted to ICOIN 2022. (Congrats Jongmin!)","tags":["Accepted","ICOIN","Conference","Workshop"],"title":"One paper accepted to ICOIN 2022","type":"post"},{"authors":["Gunjae Koo"],"categories":["Funding"],"content":"Computer System Architecture (CSArch) Lab received the Korea University Insung Research Grant to support the research on near data processing for genome analytics. We want to express our sincere gratitude to generous supporters who have contributed to Korea University.\n","date":1638316800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1638316800,"objectID":"7fde4e0b0e2a8bceea4fb3d0fc05c41c","permalink":"https://ku-csarch.github.io/post/grant-insung21/","publishdate":"2021-12-01T00:00:00Z","relpermalink":"/post/grant-insung21/","section":"post","summary":"Our lab received funding from Korea University to support the research on near data processing for genome analytics.","tags":["Funding","Grant"],"title":"Received the Korea University Insung Research Grant","type":"post"},{"authors":["Gunjae Koo","Jongmin Lee"],"categories":["Conference"],"content":"Two papers were accepted to the Design, Automation and Test in Europe Conference (DATE) 2022. One paper proposes CacheRewinder, an efficient architectural defense mechanism against transient execution attacks. CacheRewinder exploits the underutilized write-back buffer entries to revoke cache updates done by speculative executions. Another paper presents Stealth ECC, a cost-effective and strong memory protection scheme. Stealth ECC exploits not-meaningful data fields to provide stronger error correction capability.\n","date":1636588800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1636588800,"objectID":"6c0d2aebdab90ea1ea6e8261995b4cd5","permalink":"https://ku-csarch.github.io/post/accepted-date22/","publishdate":"2021-11-11T00:00:00Z","relpermalink":"/post/accepted-date22/","section":"post","summary":"Our paper on secure architecture against transient execution attacks was accepted to DATE 2022. (Congrats Jongmin!) Another paper on an efficient DRAM ECC scheme was also accepted. (Congrats Young Seo!)","tags":["Accepted","DATE","Conference"],"title":"Two papers accepted to DATE 2022","type":"post"},{"authors":["Minkyu Song","Junyeon Lee","Taeweon Suh","Gunjae Koo"],"categories":null,"content":"","date":1636502400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1636502400,"objectID":"23493c2333e9128b45959d57d363f794","permalink":"https://ku-csarch.github.io/publication/sec_cache_mdpi21/","publishdate":"2021-11-10T00:00:00Z","relpermalink":"/publication/sec_cache_mdpi21/","section":"publication","summary":"Since cache side-channel attacks have been serious security threats to multi-tenant systems, there have been several studies to protect systems against the attacks. However, the prior studies have limitations in determining only the existence of the attack and/or occupying too many computing resources in runtime. We propose a low-overhead pinpointing solution, called RT-Sniper, to overcome such limitations. RT-Sniper employs a two-level filtering mechanism to minimize performance overhead. It first monitors hardware events per core and isolates a suspected core to run a malicious process. Then among the processes running on the selected core, RT-Sniper pinpoints a malicious process through a per-process monitoring approach. With the core-level filtering, RT-Sniper has an advantage in overhead compared to the previous works. We evaluate RT-Sniper against Flush+Reload and Prime+Probe attacks running SPEC2017, LMBench, and PARSEC benchmarks on multi-core systems. Our evaluation demonstrates that the performance overhead by RT-Sniper is negligible (0.3% for single-threaded applications and 2.05% for multi-threaded applications). Compared to the previous defense solutions against cache side-channel attacks, RT-Sniper exhibits better detection performance with lower performance overhead.","tags":["Security","Malware Detection","Cache Side-Channel Attack","Low-Overhead"],"title":"RT-Sniper: A Low-Overhead Defense Mechanism Pinpointing Cache Side-Channel Attacks","type":"publication"},{"authors":["Gunjae Koo"],"categories":["Journal"],"content":"One paper was accepted to MDPI Electronics. Our paper proposes RT-Sniper, a software-based lightweight defense solution against cache side-channel attacks. RT-Sniper pinpoints attack processes efficiently using a two-phased monitoring mechanism: core-level and process-level profiling. Hence, RT-Sniper can effectively detect malicious processes with negligible performance overhead.\n","date":1636156800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1636156800,"objectID":"02e89bff48fc817d109d6e46a5c0b9b0","permalink":"https://ku-csarch.github.io/post/accepted-mdpi21/","publishdate":"2021-11-06T00:00:00Z","relpermalink":"/post/accepted-mdpi21/","section":"post","summary":"Our paper on a software-based defense solution against cache side-channel attacks was accepted to MDPI Electronics. (Congrats Minkyu and Junyeon!)","tags":["Accepted","MDPI Electronics","Journal"],"title":"One paper accepted to MDPI Electronics (Journal, SCIE)","type":"post"},{"authors":["Hunjong Lee","Hyunwoo Moon"],"categories":["Join"],"content":"Hunjong and Hyunwoo have joined CSArch Lab since the Fall semester 2021. We hope they will enjoy adventures in computer architecture research. Welcome!!\n","date":1630454400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1630454400,"objectID":"b2b4dedfd21b07e32b84b4702a02913b","permalink":"https://ku-csarch.github.io/post/join-lab21fa/","publishdate":"2021-09-01T00:00:00Z","relpermalink":"/post/join-lab21fa/","section":"post","summary":"Hunjong and Hyunwoo have joined CSArch Lab. Welcome aboard!!","tags":["Join"],"title":"Hunjong and Hyunwoo have joined CSArch Lab","type":"post"},{"authors":["Gunjae Koo"],"categories":["Funding"],"content":"Computer System Architecture (CSArch) Lab was awarded the innovative research lab initiation grant (최초혁신실험실) from National Research Foundation (NRF). The grant will allow us to set up fundamental research equipments for research on processor and memory system architecture. The amount of the grant is approximately $100,000. Thanks NRF!\n","date":1625097600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1625097600,"objectID":"33b44040598aa0eeec037843f3ef14c7","permalink":"https://ku-csarch.github.io/post/award-nrf21/","publishdate":"2021-07-01T00:00:00Z","relpermalink":"/post/award-nrf21/","section":"post","summary":"Our lab was awarded the innovative research lab initiation grant (최초혁신실험실) from National Research Foundation (NRF).","tags":["Funding","Award"],"title":"Awarded the innovative research lab initiation grant (최초혁신실험실) from NRF","type":"post"},{"authors":["Gunjae Koo","Inje Kim"],"categories":["Conference (Korea)"],"content":"Inje presented his research on the characteristics of GCN inference models at Korea Computer Congress 2021 (KCC 2021) held in Seoguipo-si, Jeju-do. Our lab members also attended the conference to have a great time. Good job, Inje!\n","date":1624579200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1624579200,"objectID":"4f5352cde1b37799dd5451eb86be806a","permalink":"https://ku-csarch.github.io/post/present-kcc21/","publishdate":"2021-06-25T00:00:00Z","relpermalink":"/post/present-kcc21/","section":"post","summary":"Inje presented his research on the characteristics of GCN inference models at Korea Computer Congress (KCC) 2021.","tags":["Talk","Conference (Korea)"],"title":"Inje presented at KCC 2021","type":"post"},{"authors":["Inje Kim","Gunjae Koo"],"categories":null,"content":"","date":1624579200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1624579200,"objectID":"5e90c8f60397bfcb33d322a2c8fc45e1","permalink":"https://ku-csarch.github.io/publication/gnn_profile_kcc21/","publishdate":"2021-06-25T00:00:00Z","relpermalink":"/publication/gnn_profile_kcc21/","section":"publication","summary":"Graph Convolutional Neural Network (GCN)은 그래프 구조를 이용한 인공 신경망 (Graph Neural Network, GNN) 중의 하나로서 소셜 네트워크 분석 및 소비자 성향 분석, 추천 시스템 등의 여러 응용 분야에 이용될 수 있다. GCN은 비유클리드형 자료 구조의 형태를 가지는 그래프 구조에 대한 데이터 처리를 요구하기 때문에 기존의 Deep Neural Network (DNN)에 사용되는 데이터와는 차이점을 가지고 있다. 그렇기 때문에, GCN을 기존의 DNN을 처리하는 데에 주로 쓰이는 하드웨어 구조에서 실행했을 때의 특성을 분석하는 것은 향후 효과적인 GCN용 알고리즘 및 하드웨어를 설계하는 데에 있어서 필수적이다. 본 연구에서는 인공 신경망 구조를 처리하는 데에 주로 쓰이는 GPU에서 여러가지 GCN 추론 알고리즘을 실행하고 이를 GPU 프로파일러로 분석하여 해당 하드웨어 구조에서 GCN 추론 커널이 가지는 특성을 밝히고 있다. 본 연구에서는 GCN 추론 과정에 쓰이는 커널들이 크게 두 종류의 큰 차이를 보이는 특성을 보이는 커널들로 분류할 수 있음을 밝히고 있으며, 이러한 특성에 기반하여 GCN의 커널들이 GPU에서 실행 엔진과 캐시 메모리와 같은 하드웨어 자원을 비효율적으로 사용하고 있음을 밝혀내었다. 본 연구를 통하여 GCN의 최적화 방법 및 GCN을 효율적으로 실행하기 위한 구조적인 접근 방법에 대해서 도움을 줄 수 있다.","tags":["GNN","Profiling","GPU"],"title":"Revealing Characteristics of GCN Inference Models Using a GPU Profiler","type":"publication"},{"authors":["Inje Kim","Boyoung Park","Jonghyun Jeong"],"categories":["Join"],"content":"Inje, Boyoung, and Jonghyun have joined CSArch Lab since the Fall semester 2021. We hope they will enjoy adventures in computer architecture research. Welcome!!\n","date":1614556800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1614556800,"objectID":"de8e6c87acaed2c75fbc30e2402ba1c0","permalink":"https://ku-csarch.github.io/post/join-lab21sp/","publishdate":"2021-03-01T00:00:00Z","relpermalink":"/post/join-lab21sp/","section":"post","summary":"Inje, Boyoung, and Jonghyun have joined CSArch Lab. Welcome aboard!!","tags":["Join"],"title":"Inje, Boyoung, and Jonghyun have joined CSArch Lab","type":"post"},{"authors":["Gunjae Koo"],"categories":["Funding"],"content":"Computer System Architecture (CSArch) Lab received funding from National Research Foundation (NRF) to support the research on the processor and memory architecture for neural networks using large graph structures. Prof. Gunjae Koo was awarded the outstanding young scientist grant (우수신진연구) which is a part of Basic Research Projects funded by Korean government. Thanks NRF!\n","date":1614556800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1614556800,"objectID":"3fe0e74b9aa29558523df71105f035c3","permalink":"https://ku-csarch.github.io/post/grant-nrf21/","publishdate":"2021-03-01T00:00:00Z","relpermalink":"/post/grant-nrf21/","section":"post","summary":"Our lab received funding from National Research Foundation (NRF) to support the research on processor and memory architecture for neural networks using large graph structures.","tags":["Funding","Grant"],"title":"Received the outstanding young scientist grant (우수신진연구) from NRF","type":"post"},{"authors":["Murali Annavaram","Gunjae Koo","Kiran Kumar Matam","Hung-Wei Tseng"],"categories":null,"content":"","date":1601510400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1601510400,"objectID":"f4f9573d803f140024d1a7e7596f163b","permalink":"https://ku-csarch.github.io/publication/ssd_proc_patent20/","publishdate":"2020-10-01T00:00:00Z","relpermalink":"/publication/ssd_proc_patent20/","section":"publication","summary":"Publication of US20200310690A1","tags":["SSD","Near Data Processing","Dynamic Workload Offloading","Storage Systems"],"title":"Dynamic Near-Data Processing Control Mechanism Based on Computer Resource Availability on Solid-State Disk Platforms","type":"publication"},{"authors":["Seungho Jung","Jongmin Lee"],"categories":["Join"],"content":"Seungho and Jongmin have joined CSArch Lab since the Fall semester 2020. We hope they will enjoy adventures in computer architecture research. Welcome!!\n","date":1598918400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598918400,"objectID":"9dce731f1e3a7c81f2378d9ad05def1a","permalink":"https://ku-csarch.github.io/post/join-lab20fa/","publishdate":"2020-09-01T00:00:00Z","relpermalink":"/post/join-lab20fa/","section":"post","summary":"Seungho and Jongmin have joined CSArch Lab. Welcome aboard!!","tags":["Join"],"title":"Seungho and Jongmin have joined CSArch Lab","type":"post"},{"authors":["Hunjong Lee","Junhwan Yoo","Gunjae Koo"],"categories":null,"content":"","date":1597968000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1597968000,"objectID":"42a801d3bf09c312f05e61dd04ecf940","permalink":"https://ku-csarch.github.io/publication/accel_speaker_ieie20/","publishdate":"2020-08-21T00:00:00Z","relpermalink":"/publication/accel_speaker_ieie20/","section":"publication","summary":"Response time is one of the critical performance factors of artificial intelligence (AI) speakers. The internet network delays and the processing time on cloud server infrastructure dominate the response delays of AI speakers. The network delay is proportional to the size of packets that include the recorded queries. Normally this recorded sound data is not compressed since compression processes can be a heavy burden for the wimpy processors embedded in AI speakers. In this work we design an audio compression accelerator which can reduce the packet size of user queries. We implement the proposed accelerator on the FPGA-based SoC development board. Our evaluation reveals that the overall response time of an AI speaker is effectively reduced with the audio compression accelerator.","tags":["Accelerator","Compression","FPGA"],"title":"Audio Compression Accelerator Design for Improving the Response Time of AI Speakers","type":"publication"},{"authors":["Won Jeon","Jun Hyun Park","Yoonsoo Kim","Gunjae Koo","Won Woo Ro"],"categories":null,"content":"","date":1594598400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1594598400,"objectID":"765c916eb372c35c663de792f60aaa07","permalink":"https://ku-csarch.github.io/publication/gpu_nvrf_access20/","publishdate":"2020-07-13T00:00:00Z","relpermalink":"/publication/gpu_nvrf_access20/","section":"publication","summary":"Modern Graphics Processing Units (GPUs) require large hardware resources for massive parallel thread executions. In particular, modern GPUs have a large register file composed of Static Random Access Memory (SRAM). Due to the high leakage current of SRAM, the register file consumes approximately 20% of the total GPU energy. The energy efficiency of the register file becomes more critical as the throughput of GPUs increases. For more energy-efficient GPUs, the usage of non-volatile memory such as Spin-Transfer Torque Magnetic Random Access Memory (STT-MRAM) as the GPU register file has been studied extensively. STT-MRAM requires a lower leakage current compared to SRAM and provides an appropriate read performance. However, using STT-MRAM directly in the GPU register file causes problems in performance and endurance because of complicated write procedures and material characteristics. To overcome these challenges, we propose a novel register file architecture and its management system for GPUs, named Hi-End, which exploits the data locality and compressibility of the register file. For STT-MRAM-based GPU register files, Hi-End increases the data write performance and endurance by caching and data compression, respectively. In our evaluation, Hi-End enhances the energy efficiency of a GPU register file by 70.02% and reduces the write operations by up to 95.98% with negligible performance degradation compared to SRAM-based register files.","tags":["GPU","Register File","STT-MRAM","Energy Efficiency","Data Compression"],"title":"Hi-End: Hierarchical, Endurance-Aware STT-MRAM-Based Register File for Energy-Efficient GPUs","type":"publication"},{"authors":null,"categories":null,"content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1583366400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1583366400,"objectID":"5e4b501ee8b4e4874b4297df0e1b461d","permalink":"https://ku-csarch.github.io/project/dsa/","publishdate":"2020-03-05T00:00:00Z","relpermalink":"/project/dsa/","section":"project","summary":"DSAs","tags":["Deep Learning"],"title":"Domain Specific Architectures","type":"project"},{"authors":null,"categories":null,"content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1583280000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1583280000,"objectID":"82e1b13f8f0f9a6bfa30a4b6f5cd0429","permalink":"https://ku-csarch.github.io/project/parallel_processor/","publishdate":"2020-03-04T00:00:00Z","relpermalink":"/project/parallel_processor/","section":"project","summary":"Graphics processing units (GPUs) are","tags":["Deep Learning"],"title":"Parallel Processor Architecture","type":"project"},{"authors":null,"categories":null,"content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1583193600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1583193600,"objectID":"7db2bc7185e9468b82fb1e7bb47f4d8f","permalink":"https://ku-csarch.github.io/project/storage_systems/","publishdate":"2020-03-03T00:00:00Z","relpermalink":"/project/storage_systems/","section":"project","summary":"Storage devices","tags":["Deep Learning"],"title":"Storage Systems","type":"project"},{"authors":null,"categories":null,"content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1583107200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1583107200,"objectID":"19cfbba997c0a308237f06953444e243","permalink":"https://ku-csarch.github.io/project/memory_systems/","publishdate":"2020-03-02T00:00:00Z","relpermalink":"/project/memory_systems/","section":"project","summary":"Memory","tags":["Deep Learning"],"title":"Memory Systems","type":"project"},{"authors":null,"categories":null,"content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1583020800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1583020800,"objectID":"6da6aa447fe324ac679bb9487737359f","permalink":"https://ku-csarch.github.io/project/secure_processor/","publishdate":"2020-03-01T00:00:00Z","relpermalink":"/project/secure_processor/","section":"project","summary":"Hardware security","tags":["Deep Learning"],"title":"Secure Processor Architecture","type":"project"},{"authors":["Kiran Kumar Matam","Gunjae Koo","Haipeng Zha","Hung-Wei Tseng","Murali Annavaram"],"categories":null,"content":"","date":1561507200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1561507200,"objectID":"ec8af1541110f5aaf6d976193a2883b6","permalink":"https://ku-csarch.github.io/publication/ssd_graph_isca19/","publishdate":"2019-06-26T00:00:00Z","relpermalink":"/publication/ssd_graph_isca19/","section":"publication","summary":"Graph analytics play a key role in a number of applications such as social networks, drug discovery, and recommendation systems. Given the large size of graphs that may exceed the capacity of the main memory, application performance is bounded by storage access time. Out-of-core graph processing frameworks try to tackle this storage access bottleneck through techniques such as graph sharding, and sub-graph partitioning. Even with these techniques, the need to access data across different graph shards or sub-graphs causes storage systems to become a significant performance hurdle. In this paper, we propose a graph semantic aware solid state drive (SSD) framework, called GraphSSD, which is a full system solution for storing, accessing, and performing graph analytics on SSDs. Rather than treating storage as a collection of blocks, GraphSSD considers graph structure while deciding on graph layout, access, and update mechanisms. GraphSSD replaces the conventional logical to physical page mapping mechanism in an SSD with a novel vertex-to-page mapping scheme and exploits the detailed knowledge of the flash properties to minimize page accesses. GraphSSD also supports efficient graph updates (vertex and edge modifications) by minimizing unnecessary page movement overheads. GraphSSD provides a simple programming interface that enables application developers to access graphs as native data in their applications, thereby simplifying the code development. It also augments the NVMe (non-volatile memory express) interface with a minimal set of changes to map the graph access APIs to appropriate storage access mechanisms. Our evaluation results show that the GraphSSD framework improves the performance by up to 1.85 × for the basic graph data fetch functions and on average 1.40×, 1.42×, 1.60×, 1.56×, and 1.29× for the widely used breadth-first search, connected components, random-walk, maximal independent set, and page rank applications, respectively.","tags":["SSD","Storage","Graphs"],"title":"GraphSSD: Graph Semantics Aware SSD","type":"publication"},{"authors":["Yunho Oh","Gunjae Koo","Murali Annavaram","Won Woo Ro"],"categories":null,"content":"","date":1561507200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1561507200,"objectID":"76ff69ce7d7740542ffe998f1d3cd677","permalink":"https://ku-csarch.github.io/publication/gpu_lb_isca19/","publishdate":"2019-06-26T00:00:00Z","relpermalink":"/publication/gpu_lb_isca19/","section":"publication","summary":"Modern GPUs suffer from cache contention due to the limited cache size that is shared across tens of concurrently running warps. To increase the per-warp cache size prior techniques proposed warp throttling which limits the number of active warps. Warp throttling leaves several registers to be dynamically unused whenever a warp is throttled. Given the stringent cache size limitation in GPUs this work proposes a new cache management technique named Linebacker (LB) that improves GPU performance by utilizing idle register file space as victim cache space. Whenever a CTA becomes inactive, linebacker backs up the registers of the throttled CTA to the off-chip memory. Then, linebacker utilizes the corresponding register file space as victim cache space. If any load instruction finds data in the victim cache line, the data is directly copied to the destination register through a simple register-register move operation. To further improve the efficiency of victim cache linebacker allocates victim cache space only to a select few load instructions that exhibit high data locality. Through a careful design of victim cache indexing and management scheme linebacker provides 29.0% of speedup compared to the previously proposed warp throttling techniques.","tags":["GPU","Cache","Register File","Scheduling"],"title":"Linebacker: Preserving Victim Cache Lines in Idle Register Files of GPUs","type":"publication"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Wowchemy Wowchemy | Documentation\n Features  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides   Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E   Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026#34;blueberry\u0026#34; if porridge == \u0026#34;blueberry\u0026#34;: print(\u0026#34;Eating...\u0026#34;)  Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\n Fragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}} Press Space to play!\nOne  Two  Three   A fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears   Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}} Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view    Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links    night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links   Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026#34;/media/boards.jpg\u0026#34; \u0026gt;}} {{\u0026lt; slide background-color=\u0026#34;#0000FF\u0026#34; \u0026gt;}} {{\u0026lt; slide class=\u0026#34;my-style\u0026#34; \u0026gt;}}  Custom CSS Example Let’s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }  Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"https://ku-csarch.github.io/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Wowchemy's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":["Gunjae Koo","Vivek Kozhikkottu","Shankar Ganesh Ramasubramanian","Christopher B. Wilkerson"],"categories":null,"content":"","date":1530748800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1530748800,"objectID":"23df7bd59ce22924ba0584ebd4faa8e3","permalink":"https://ku-csarch.github.io/publication/dram_ctrl_patent18/","publishdate":"2018-07-05T00:00:00Z","relpermalink":"/publication/dram_ctrl_patent18/","section":"publication","summary":"Publication of US20180188976A1","tags":["DRAM","Memory Controller"],"title":"Increasing Read Pending Queue Capacity to Increase Memory Bandwidth","type":"publication"},{"authors":["Gunjae Koo","Hyeran Jeon","Zhenhong Liu","Nam Sung Kim","Murali Annavaram"],"categories":null,"content":"","date":1527206400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1527206400,"objectID":"e845389df646b79218cb072a93488682","permalink":"https://ku-csarch.github.io/publication/gpu_caps_ipdps18/","publishdate":"2018-05-25T00:00:00Z","relpermalink":"/publication/gpu_caps_ipdps18/","section":"publication","summary":"Albeit GPUs are supposed to be tolerant to long latency of data fetch operation, we observe that L1 cache misses occur in a bursty manner for many memory-intensive applications. This in turn leads to severe contentions in GPU memory hierarchy, and thus stalls execution pipeline for many cycles as all warps end up waiting for their memory requests to be serviced by L1 cache. To spread such bursty L1 cache misses, we propose CTA-Aware Prefetcher and Scheduler (CAPS) consisting of a thread group-aware prefetcher and a prefetch-aware warp scheduler for GPUs. GPU kernels group threads into cooperative thread arrays (CTAs). Each thread typically uses its thread index and its associated CTA index to identify the data that it operates on. The starting base address accessed by the first warp in a CTA is difficult to predict since that starting address is a complex function of thread index and CTA index and also depends on how the programmer distributes input data across CTAs. But threads within each CTA exhibit stride accesses. Hence, if the base address of each CTA can be computed early, it is possible to accurately predict prefetch addresses for threads within a CTA. To compute the base address of each CTA, a leading warp is used from each CTA. The leading warp is executed early by pairing it with warps from currently executing leading CTA. The warps in the leading CTA are used to compute the stride value. The stride value is then combined with base addresses computed from the leading warp of each CTA to prefetch the data for all the trailing warps in the trailing CTAs. CAPS allows prefetch requests to be issued sufficiently ahead of time before the demand requests, effectively reorganizing warp executions to quickly detect the base address of each CTA and stride per load. CAPS predicts addresses with over 97% accuracy and is able to improve GPU performance by 8% on average with up to 27% for a wide range of GPU applications.","tags":["GPU","Prefetch","SIMT","Scheduling"],"title":"CTA-Aware Prefetching and Scheduling for GPU","type":"publication"},{"authors":["Gunjae Koo","Kiran Kumar Matam","Te I","H. V. Krishna Giri Narra","Jing Li","Hung-Wei Tseng","Steven Swanson","Murali Annavaram"],"categories":null,"content":"","date":1507939200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1507939200,"objectID":"09aafa67eeef59c83f6c202da80779f9","permalink":"https://ku-csarch.github.io/publication/ssd_proc_micro17/","publishdate":"2017-10-14T00:00:00Z","relpermalink":"/publication/ssd_proc_micro17/","section":"publication","summary":"Modern data center solid state drives (SSDs) integrate multiple general-purpose embedded cores to manage flash translation layer, garbage collection, wear-leveling, and etc., to improve the performance and the reliability of SSDs. As the performance of these cores steadily improves there are opportunities to repurpose these cores to perform application driven computations on stored data, with the aim of reducing the communication between the host processor and the SSD. Reducing host-SSD bandwidth demand cuts down the I/O time which is a bottleneck for many applications operating on large data sets. However, the embedded core performance is still significantly lower than the host processor, as generally wimpy embedded cores are used within SSD for cost effective reasons. So there is a trade-off between the computation overhead associated with near SSD processing and the reduction in communication overhead to the host system. In this work, we design a set of application programming interfaces (APIs) that can be used by the host application to offload a data intensive task to the SSD processor. We describe how these APIs can be implemented by simple modifications to the existing Non-Volatile Memory Express (NVMe) command interface between the host and the SSD processor. We then quantify the computation versus communication tradeoffs for near storage computing using applications from two important domains, namely data analytics and data integration. Using a fully functional SSD evaluation platform we perform design space exploration of our proposed approach by varying the bandwidth and computation capabilities of the SSD processor. We evaluate static and dynamic approaches for dividing the work between the host and SSD processor, and show that our design may improve the performance by up to 20% when compared to processing at the host processor only, and 6X when compared to processing at the SSD processor only.","tags":["SSD","Near Data Processing","Dynamic Workload Offloading","Storage Systems"],"title":"Summarizer: Trading Communication with Computing near Storage","type":"publication"},{"authors":["Gunjae Koo","Yunho Oh","Won Woo Ro","Murali Annavaram"],"categories":null,"content":"","date":1498262400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1498262400,"objectID":"7a907e2f414f462709e2fb7e9b5b5b25","permalink":"https://ku-csarch.github.io/publication/gpu_apcm_isca17/","publishdate":"2017-06-24T00:00:00Z","relpermalink":"/publication/gpu_apcm_isca17/","section":"publication","summary":"Long latency of memory operation is a prominent performance bottleneck in graphics processing units (GPUs). The small data cache that must be shared across dozens of warps (a collection of threads) creates significant cache contention and premature data eviction. Prior works have recognized this problem and proposed warp throttling which reduces the number of active warps contending for cache space. In this paper we discover that individual load instructions in a warp exhibit four different types of data locality behavior: (1) data brought by a warp load instruction is used only once, which is classified as streaming data (2) data brought by a warp load is reused multiple times within the same warp, called intra-warp locality (3) data brought by a warp is reused multiple times but across different warps, called inter-warp locality (4) and some data exhibit both a mix of intra- and inter-warp locality. Furthermore, each load instruction exhibits consistently the same locality type across all warps within a GPU kernel. Based on this discovery we argue that cache management must be done using per-load locality type information, rather than applying warp-wide cache management policies. We propose Access Pattern-aware Cache Management (APCM), which dynamically detects the locality type of each load instruction by monitoring the accesses from one exemplary warp. APCM then uses the detected locality type to selectively apply cache bypassing and cache pinning of data based on load locality characterization. Using an extensive set of simulations we show that APCM improves performance of GPUs by 34% for cache sensitive applications while saving 27% of energy consumption over baseline GPU.","tags":["GPU","Cache","Access Pattern"],"title":"Access Pattern-Aware Cache Management for Improving Data Utilization in GPU","type":"publication"},{"authors":["Sangpil Lee","Keunsoo Kim","Gunjae Koo","Hyeran Jeon","Won Woo Ro","Murali Annavaram"],"categories":null,"content":"","date":1493596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1493596800,"objectID":"30b783f252515ef46b96a430ade15c3a","permalink":"https://ku-csarch.github.io/publication/gpu_rfcomp_tc17/","publishdate":"2017-05-01T00:00:00Z","relpermalink":"/publication/gpu_rfcomp_tc17/","section":"publication","summary":"GPU design trends show that the register file size will continue to increase to enable even more thread level parallelism. As a result register file consumes a large fraction of the total GPU chip power. This paper explores register file data compression for GPUs to improve power efficiency. Compression reduces the width of the register file read and write operations, which in turn reduces dynamic power. This work is motivated by the observation that the register values of threads within the same warp are similar, namely the arithmetic differences between two successive thread registers is small. Compression exploits the value similarity by removing data redundancy of register values. Without decompressing operand values some instructions can be processed inside register file, which enables to further save energy by minimizing data movement and processing in power hungry main execution unit. Evaluation results show that the proposed techniques save 25 percent of the total register file energy consumption and 21 percent of the total execution unit energy consumption with negligible performance impact.","tags":["GPU","Register File","Energy Efficiency","Data Compression"],"title":"Improving Energy Efficiency of GPUs through Data Compression and Compressed Execution","type":"publication"},{"authors":["Keunsoo Kim","Sangpil Lee","Myung Kuk Yoon","Gunjae Koo","Won Woo Ro","Murali Annavaram"],"categories":null,"content":"","date":1458086400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1458086400,"objectID":"be7823eb0c03c5f8ac83ba7be459d739","permalink":"https://ku-csarch.github.io/publication/gpu_pwarp_hpca16/","publishdate":"2016-03-16T00:00:00Z","relpermalink":"/publication/gpu_pwarp_hpca16/","section":"publication","summary":"This paper presents a pre-execution approach for improving GPU performance, called P-mode (pre-execution mode). GPUs utilize a number of concurrent threads for hiding processing delay of operations. However, certain long-latency operations such as off-chip memory accesses often take hundreds of cycles and hence leads to stalls even in the presence of thread concurrency and fast thread switching capability. It is unclear if adding more threads can improve latency tolerance due to increased memory contention. Further, adding more threads increases on-chip storage demands. Instead we propose that when a warp is stalled on a long-latency operation it enters P-mode. In P-mode, a warp continues to fetch and decode successive instructions to identify any independent instruction that is not on the long latency dependence chain. These independent instructions are then pre-executed. To tackle write-after-write and write-after-read hazards, during P-mode output values are written to renamed physical registers. We exploit the register file underutilization to re-purpose a few unused registers to store the P-mode results. When a warp is switched from P-mode to normal execution mode it reuses pre-executed results by reading the renamed registers. Any global load operation in P-mode is transformed into a pre-load which fetches data into the L1 cache to reduce future memory access penalties. Our evaluation results show 23% performance improvement for memory intensive applications, without negatively impacting other application categories.","tags":["GPU","SIMT","Scheduling"],"title":"Warped-Preexecution: A GPU Pre-Execution Approach for Improving Latency Hiding","type":"publication"},{"authors":["Gunjae Koo","Hyeran Jeon","Murali Annavaram"],"categories":null,"content":"","date":1444089600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1444089600,"objectID":"d361d1c6b955a2287ef9a802c0490812","permalink":"https://ku-csarch.github.io/publication/gpu_load_iiswc15/","publishdate":"2015-10-06T00:00:00Z","relpermalink":"/publication/gpu_load_iiswc15/","section":"publication","summary":"In graphics processing units (GPUs), memory access latency is one of the most critical performance hurdles. Several warp schedulers and memory prefetching algorithms have been proposed to avoid the long memory access latency. Prior application characterization studies shed light on the interaction between applications, GPU micro architecture and memory subsystem behavior. Most of these studies, however, only present aggregate statistics on how memory system behaves over the entire application run. In particular, they do not consider how individual load instructions in a program contribute to the aggregate memory system behavior. The analysis presented in this paper shows that there are two distinct classes of load instructions, categorized as deterministic and non-deterministic loads. Using a combination of profiling data from a real GPU card and cycle accurate simulation data we show that there is a significant performance impact disparity when executing these two types of loads. We discuss and suggest several approaches to treat these two load categories differently within the GPU micro architecture for optimizing memory system performance.","tags":["GPU","Load","Cache","Scheduling"],"title":"Revealing Critical Loads and Hidden Data Locality in GPGPU Applications","type":"publication"},{"authors":["Sangpil Lee","Keunsoo Kim","Gunjae Koo","Hyeran Jeon","Won Woo Ro","Murali Annavaram"],"categories":null,"content":"","date":1434153600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1434153600,"objectID":"a02f42b3074871a4c97b3ab7947453da","permalink":"https://ku-csarch.github.io/publication/gpu_rfcomp_isca15/","publishdate":"2015-06-13T00:00:00Z","relpermalink":"/publication/gpu_rfcomp_isca15/","section":"publication","summary":"This paper presents Warped-Compression, a warp-level register compression scheme for reducing GPU power consumption. This work is motivated by the observation that the register values of threads within the same warp are similar, namely the arithmetic differences between two successive thread registers is small. Removing data redundancy of register values through register compression reduces the effective register width, thereby enabling power reduction opportunities. GPU register files are huge as they are necessary to keep concurrent execution contexts and to enable fast context switching. As a result register file consumes a large fraction of the total GPU chip power. GPU design trends show that the register file size will continue to increase to enable even more thread level parallelism. To reduce register file data redundancy warped-compression uses low-cost and implementation-efficient base-delta-immediate (BDI) compression scheme, that takes advantage of banked register file organization used in GPUs. Since threads within a warp write values with strong similarity, BDI can quickly compress and decompress by selecting either a single register, or one of the register banks, as the primary base and then computing delta values of all the other registers, or banks. Warped-compression can be used to reduce both dynamic and leakage power. By compressing register values, each warp-level register access activates fewer register banks, which leads to reduction in dynamic power. When fewer banks are used to store the register content, leakage power can be reduced by power gating the unused banks. Evaluation results show that register compression saves 25% of the total register file power consumption.","tags":["GPU","Register File","Data Compression","Energy Efficiency"],"title":"Warped-Compression: Enabling Power Efficient GPUs through Register Compression","type":"publication"},{"authors":["Gunjae Koo","Kyoung Won Lim","Seung Jong Choi"],"categories":null,"content":"","date":1294790400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1294790400,"objectID":"dde6824d6d30706ce68b1b9bb97eb727","permalink":"https://ku-csarch.github.io/publication/frc_icce11/","publishdate":"2011-01-12T00:00:00Z","relpermalink":"/publication/frc_icce11/","section":"publication","summary":"In this paper, we present complementary motion estimation algorithm for motion compensated frame rate up-conversion. The proposed algorithm combines forward and backward motion estimation results to make up for the weakness of each motion estimation method. It also allocates true motion vectors in occlusion regions by using the temporal relations of the forward and backward motion estimation. Thus, we reduce artifacts by false motion vectors near occlusion regions in a compensated frame.","tags":["Image Processing","Motion Estimation","Frame Rate Conversion"],"title":"Complementary Block-Based Motion Estimation for Frame Rate Up-Conversion","type":"publication"},{"authors":["Gunjae Koo","Woochul Jung","Heesub Lee"],"categories":null,"content":"","date":1148428800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1148428800,"objectID":"0f7af2cebe0b90ecab9c7f6d32940c26","permalink":"https://ku-csarch.github.io/publication/prml_iscas06/","publishdate":"2006-05-24T00:00:00Z","relpermalink":"/publication/prml_iscas06/","section":"publication","summary":"In this paper, a PRML read channel that supports multiple optical disc formats, i.e. CD, DVD and BD is presented. The read channel includes digital timing recovery that generates timing matched data by interpolation, which can acquire high controllability and stability with small hardware. PRML bit detection is applied to the read channel in order to reduce bit errors for severe channel condition such as BD and high speed DVD. Also, PR-level of PRML is adaptively controlled to compensate asymmetry and signal level shift due to defects. To support high operating speed, the read channel is designed in a 2times-parallel processing. The read channel uses a 115 MHz main clock, and can support up to 8times DVD, equivalent to a channel rate of 210 MHz","tags":["PRML","Read Channel","Timing Recovery"],"title":"A Robust PRML Read Channel with Digital Timing Recovery for Multi-Format Optical Disc","type":"publication"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"f26b5133c34eec1aa0a09390a36c2ade","permalink":"https://ku-csarch.github.io/admin/config.yml","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/admin/config.yml","section":"","summary":"","tags":null,"title":"","type":"wowchemycms"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"6d99026b9e19e4fa43d5aadf147c7176","permalink":"https://ku-csarch.github.io/contact/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/contact/","section":"","summary":"","tags":null,"title":"","type":"widget_page"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"665288c8761d48eb3366c37954243edc","permalink":"https://ku-csarch.github.io/gallery/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/gallery/","section":"","summary":"","tags":null,"title":"","type":"widget_page"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"c1d17ff2b20dca0ad6653a3161942b64","permalink":"https://ku-csarch.github.io/people/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/","section":"","summary":"","tags":null,"title":"","type":"widget_page"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"f1d044c0738ab9f19347f15c290a71a1","permalink":"https://ku-csarch.github.io/research/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/research/","section":"","summary":"","tags":null,"title":"","type":"widget_page"}]